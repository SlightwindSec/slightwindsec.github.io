<!DOCTYPE html>
<html lang="en" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>Notes: Kaggle Courses - Intro to DL &amp; Computer Vision | Slightwind</title>
<meta name="keywords" content="Notes, Kaggle, DL, Computer Vision">
<meta name="description" content="Intro to Deep Learning A Single Neuron The Linear Unit 下面是一个neuron（或称unit）的示意图，x是输入；w是x的权重weight；b是bias，是一种特殊的权重，没有和bias相关的输入数据，它可以独立于输入修改输出。神经网络通过修改权重来“learn”。
y是这个神经元输出的值，$y=wx&#43;b$，刚好是一个直线的方程，w是斜率，b是在y轴上的截距。
Example - The Linear Unit as a Model 单个神经元是通常只会在更大的网络中发挥作用，单神经元模型是线性模型。当$w=2.5, b=90$时，这个线性模型可以用来反应糖&#39;sugars&#39;和卡路里&#39;calories&#39;的关系：
Multiple Inputs 对于多个输入，也是这样将每个输入乘以权重，并把它们相加。下面这个对应的公式为：$y=w_{0} x_{0}&#43;w_{1} x_{1}&#43;w_{2} x_{2}&#43;b.$ Linear Units in Keras 在Keras中创建模型最简单的方法是使用keras.Sequential，下面这个示例表示一个线性模型，可以输入3个特征（&lsquo;sugars&rsquo;, &lsquo;fiber&rsquo;, &lsquo;protein&rsquo;），并且只有一个输出：&lsquo;calories&rsquo;。
from tensorflow import keras from tensorflow.keras import layers # Create a network with 1 linear unit model = keras.Sequential([ layers.Dense(units=1, input_shape=[3]) ]) 第一个参数units定义输出的个数，input_shape告诉Keras输入特征的数量。目前只需要用到input_shape=[num_columns]，input_shape还可以支持使用更复杂的数据：[height, width, channels]。
Tensors是TensorFlow版本的numpy数组，并且做了一些使它更适合用于机器学习的改变，Tensors与GPU/TPU加速器兼容，而TPU就是专为Tensors而设计的。在Keras内部，使用Tensors表示神经网络的权重。
model.weights可以用来查看权重，在训练开始前，权重都会被初始化为随机值。
Deep Neural Networks Layers 神经网络会将神经元组成层（layers），合并有相同的输入的线性神经元，就得到了一个稠密层（dense layer） The Activation Function 两个中间没有其他东西的稠密层，效果并不会比一个稠密层的效果好多少，“稠密层本身不能带我们离开线和面的世界”，我们需要的是非线性（nonlinear），需要激活函数（activation function）。">
<meta name="author" content="Slightwind">
<link rel="canonical" href="https://blog.slightwind.cn/posts/tutorial/notes-kaggle-courses-intro-to-dl/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.c7114bf2e60e294d9801cc3e33241fb43d14d31c3f547fb2668595a22e5fb442.css" integrity="sha256-xxFL8uYOKU2YAcw&#43;MyQftD0U0xw/VH&#43;yZoWVoi5ftEI=" rel="preload stylesheet" as="style">
<script defer crossorigin="anonymous" src="/assets/js/highlight.f413e19d0714851f6474e7ee9632408e58ac146fbdbe62747134bea2fa3415e0.js" integrity="sha256-9BPhnQcUhR9kdOfuljJAjlisFG&#43;9vmJ0cTS&#43;ovo0FeA="
    onload="hljs.initHighlightingOnLoad();"></script>
<link rel="icon" href="https://blog.slightwind.cn/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="https://blog.slightwind.cn/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://blog.slightwind.cn/favicon-32x32.png">
<link rel="apple-touch-icon" href="https://blog.slightwind.cn/apple-touch-icon.png">
<link rel="mask-icon" href="https://blog.slightwind.cn/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --hljs-bg: #282c34;
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript>
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css" integrity="sha384-n8MVd4RsNIU0tAv4ct0nTaAbDJwPJzDEaqSD1odI+WdtXRGWt2kTvGFasHpSy3SV" crossorigin="anonymous">
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js" integrity="sha384-XjKyOOlGwcjNTAIQHIpgOno0Hl1YQqzUOEleOLALmuqehneUG+vnGctmUb0ZY0l8" crossorigin="anonymous"></script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js" integrity="sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05" crossorigin="anonymous"></script>
<script>
    document.addEventListener("DOMContentLoaded", function() {
        renderMathInElement(document.body, {
          
          
          delimiters: [
                {left: '$$', right: '$$', display: true},
                {left: '$', right: '$', display: false},
                {left: '\\(', right: '\\)', display: false},
                {left: '\\[', right: '\\]', display: false},
                {left: "\\begin{equation}", right: "\\end{equation}", display: true},
                {left: "\\begin{align}", right: "\\end{align}", display: true},
                {left: "\\begin{aligned}", right: "\\end{aligned}", display: true},
                {left: "\\begin{alignat}", right: "\\end{alignat}", display: true},
                {left: "\\begin{gather}", right: "\\end{gather}", display: true},
                {left: "\\begin{CD}", right: "\\end{CD}", display: true},
                {left: "\\[", right: "\\]", display: true}
          ],
          
          throwOnError : false
        });
    });
</script>

<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.1/highlight.min.js" integrity="sha512-Ypjm0o7jOxAd4hpdoppSEN0TQOC19UtPAqD+4s5AlXmUvbmmS/YMxYqAqarQYyxTnB6/rqip9qcxlNB/3U9Wdg==" crossorigin="anonymous" referrerpolicy="no-referrer"></script>
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.1/styles/atom-one-dark.min.css" integrity="sha512-Fcqyubi5qOvl+yCwSJ+r7lli+CO1eHXMaugsZrnxuU4DVpLYWXTVoHy55+mCb4VZpMgy7PBhV7IiymC0yu9tkQ==" crossorigin="anonymous" referrerpolicy="no-referrer" />

<meta property="og:title" content="Notes: Kaggle Courses - Intro to DL &amp; Computer Vision" />
<meta property="og:description" content="Intro to Deep Learning A Single Neuron The Linear Unit 下面是一个neuron（或称unit）的示意图，x是输入；w是x的权重weight；b是bias，是一种特殊的权重，没有和bias相关的输入数据，它可以独立于输入修改输出。神经网络通过修改权重来“learn”。
y是这个神经元输出的值，$y=wx&#43;b$，刚好是一个直线的方程，w是斜率，b是在y轴上的截距。
Example - The Linear Unit as a Model 单个神经元是通常只会在更大的网络中发挥作用，单神经元模型是线性模型。当$w=2.5, b=90$时，这个线性模型可以用来反应糖&#39;sugars&#39;和卡路里&#39;calories&#39;的关系：
Multiple Inputs 对于多个输入，也是这样将每个输入乘以权重，并把它们相加。下面这个对应的公式为：$y=w_{0} x_{0}&#43;w_{1} x_{1}&#43;w_{2} x_{2}&#43;b.$ Linear Units in Keras 在Keras中创建模型最简单的方法是使用keras.Sequential，下面这个示例表示一个线性模型，可以输入3个特征（&lsquo;sugars&rsquo;, &lsquo;fiber&rsquo;, &lsquo;protein&rsquo;），并且只有一个输出：&lsquo;calories&rsquo;。
from tensorflow import keras from tensorflow.keras import layers # Create a network with 1 linear unit model = keras.Sequential([ layers.Dense(units=1, input_shape=[3]) ]) 第一个参数units定义输出的个数，input_shape告诉Keras输入特征的数量。目前只需要用到input_shape=[num_columns]，input_shape还可以支持使用更复杂的数据：[height, width, channels]。
Tensors是TensorFlow版本的numpy数组，并且做了一些使它更适合用于机器学习的改变，Tensors与GPU/TPU加速器兼容，而TPU就是专为Tensors而设计的。在Keras内部，使用Tensors表示神经网络的权重。
model.weights可以用来查看权重，在训练开始前，权重都会被初始化为随机值。
Deep Neural Networks Layers 神经网络会将神经元组成层（layers），合并有相同的输入的线性神经元，就得到了一个稠密层（dense layer） The Activation Function 两个中间没有其他东西的稠密层，效果并不会比一个稠密层的效果好多少，“稠密层本身不能带我们离开线和面的世界”，我们需要的是非线性（nonlinear），需要激活函数（activation function）。" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://blog.slightwind.cn/posts/tutorial/notes-kaggle-courses-intro-to-dl/" /><meta property="og:image" content="https://blog.slightwind.cn/papermod-cover.png"/><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2022-03-12T16:23:00+00:00" />
<meta property="article:modified_time" content="2022-03-12T16:23:00+00:00" />

<meta name="twitter:card" content="summary_large_image"/>
<meta name="twitter:image" content="https://blog.slightwind.cn/papermod-cover.png"/>

<meta name="twitter:title" content="Notes: Kaggle Courses - Intro to DL &amp; Computer Vision"/>
<meta name="twitter:description" content="Intro to Deep Learning A Single Neuron The Linear Unit 下面是一个neuron（或称unit）的示意图，x是输入；w是x的权重weight；b是bias，是一种特殊的权重，没有和bias相关的输入数据，它可以独立于输入修改输出。神经网络通过修改权重来“learn”。
y是这个神经元输出的值，$y=wx&#43;b$，刚好是一个直线的方程，w是斜率，b是在y轴上的截距。
Example - The Linear Unit as a Model 单个神经元是通常只会在更大的网络中发挥作用，单神经元模型是线性模型。当$w=2.5, b=90$时，这个线性模型可以用来反应糖&#39;sugars&#39;和卡路里&#39;calories&#39;的关系：
Multiple Inputs 对于多个输入，也是这样将每个输入乘以权重，并把它们相加。下面这个对应的公式为：$y=w_{0} x_{0}&#43;w_{1} x_{1}&#43;w_{2} x_{2}&#43;b.$ Linear Units in Keras 在Keras中创建模型最简单的方法是使用keras.Sequential，下面这个示例表示一个线性模型，可以输入3个特征（&lsquo;sugars&rsquo;, &lsquo;fiber&rsquo;, &lsquo;protein&rsquo;），并且只有一个输出：&lsquo;calories&rsquo;。
from tensorflow import keras from tensorflow.keras import layers # Create a network with 1 linear unit model = keras.Sequential([ layers.Dense(units=1, input_shape=[3]) ]) 第一个参数units定义输出的个数，input_shape告诉Keras输入特征的数量。目前只需要用到input_shape=[num_columns]，input_shape还可以支持使用更复杂的数据：[height, width, channels]。
Tensors是TensorFlow版本的numpy数组，并且做了一些使它更适合用于机器学习的改变，Tensors与GPU/TPU加速器兼容，而TPU就是专为Tensors而设计的。在Keras内部，使用Tensors表示神经网络的权重。
model.weights可以用来查看权重，在训练开始前，权重都会被初始化为随机值。
Deep Neural Networks Layers 神经网络会将神经元组成层（layers），合并有相同的输入的线性神经元，就得到了一个稠密层（dense layer） The Activation Function 两个中间没有其他东西的稠密层，效果并不会比一个稠密层的效果好多少，“稠密层本身不能带我们离开线和面的世界”，我们需要的是非线性（nonlinear），需要激活函数（activation function）。"/>


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Posts",
      "item": "https://blog.slightwind.cn/posts/"
    }, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "Notes: Kaggle Courses - Intro to DL \u0026 Computer Vision",
      "item": "https://blog.slightwind.cn/posts/tutorial/notes-kaggle-courses-intro-to-dl/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "Notes: Kaggle Courses - Intro to DL \u0026 Computer Vision",
  "name": "Notes: Kaggle Courses - Intro to DL \u0026 Computer Vision",
  "description": "Intro to Deep Learning A Single Neuron The Linear Unit 下面是一个neuron（或称unit）的示意图，x是输入；w是x的权重weight；b是bias，是一种特殊的权重，没有和bias相关的输入数据，它可以独立于输入修改输出。神经网络通过修改权重来“learn”。\ny是这个神经元输出的值，$y=wx+b$，刚好是一个直线的方程，w是斜率，b是在y轴上的截距。\nExample - The Linear Unit as a Model 单个神经元是通常只会在更大的网络中发挥作用，单神经元模型是线性模型。当$w=2.5, b=90$时，这个线性模型可以用来反应糖'sugars'和卡路里'calories'的关系：\nMultiple Inputs 对于多个输入，也是这样将每个输入乘以权重，并把它们相加。下面这个对应的公式为：$y=w_{0} x_{0}+w_{1} x_{1}+w_{2} x_{2}+b.$ Linear Units in Keras 在Keras中创建模型最简单的方法是使用keras.Sequential，下面这个示例表示一个线性模型，可以输入3个特征（\u0026lsquo;sugars\u0026rsquo;, \u0026lsquo;fiber\u0026rsquo;, \u0026lsquo;protein\u0026rsquo;），并且只有一个输出：\u0026lsquo;calories\u0026rsquo;。\nfrom tensorflow import keras from tensorflow.keras import layers # Create a network with 1 linear unit model = keras.Sequential([ layers.Dense(units=1, input_shape=[3]) ]) 第一个参数units定义输出的个数，input_shape告诉Keras输入特征的数量。目前只需要用到input_shape=[num_columns]，input_shape还可以支持使用更复杂的数据：[height, width, channels]。\nTensors是TensorFlow版本的numpy数组，并且做了一些使它更适合用于机器学习的改变，Tensors与GPU/TPU加速器兼容，而TPU就是专为Tensors而设计的。在Keras内部，使用Tensors表示神经网络的权重。\nmodel.weights可以用来查看权重，在训练开始前，权重都会被初始化为随机值。\nDeep Neural Networks Layers 神经网络会将神经元组成层（layers），合并有相同的输入的线性神经元，就得到了一个稠密层（dense layer） The Activation Function 两个中间没有其他东西的稠密层，效果并不会比一个稠密层的效果好多少，“稠密层本身不能带我们离开线和面的世界”，我们需要的是非线性（nonlinear），需要激活函数（activation function）。",
  "keywords": [
    "Notes", "Kaggle", "DL", "Computer Vision"
  ],
  "articleBody": "Intro to Deep Learning A Single Neuron The Linear Unit 下面是一个neuron（或称unit）的示意图，x是输入；w是x的权重weight；b是bias，是一种特殊的权重，没有和bias相关的输入数据，它可以独立于输入修改输出。神经网络通过修改权重来“learn”。\ny是这个神经元输出的值，$y=wx+b$，刚好是一个直线的方程，w是斜率，b是在y轴上的截距。\nExample - The Linear Unit as a Model 单个神经元是通常只会在更大的网络中发挥作用，单神经元模型是线性模型。当$w=2.5, b=90$时，这个线性模型可以用来反应糖'sugars'和卡路里'calories'的关系：\nMultiple Inputs 对于多个输入，也是这样将每个输入乘以权重，并把它们相加。下面这个对应的公式为：$y=w_{0} x_{0}+w_{1} x_{1}+w_{2} x_{2}+b.$ Linear Units in Keras 在Keras中创建模型最简单的方法是使用keras.Sequential，下面这个示例表示一个线性模型，可以输入3个特征（‘sugars’, ‘fiber’, ‘protein’），并且只有一个输出：‘calories’。\nfrom tensorflow import keras from tensorflow.keras import layers # Create a network with 1 linear unit model = keras.Sequential([ layers.Dense(units=1, input_shape=[3]) ]) 第一个参数units定义输出的个数，input_shape告诉Keras输入特征的数量。目前只需要用到input_shape=[num_columns]，input_shape还可以支持使用更复杂的数据：[height, width, channels]。\nTensors是TensorFlow版本的numpy数组，并且做了一些使它更适合用于机器学习的改变，Tensors与GPU/TPU加速器兼容，而TPU就是专为Tensors而设计的。在Keras内部，使用Tensors表示神经网络的权重。\nmodel.weights可以用来查看权重，在训练开始前，权重都会被初始化为随机值。\nDeep Neural Networks Layers 神经网络会将神经元组成层（layers），合并有相同的输入的线性神经元，就得到了一个稠密层（dense layer） The Activation Function 两个中间没有其他东西的稠密层，效果并不会比一个稠密层的效果好多少，“稠密层本身不能带我们离开线和面的世界”，我们需要的是非线性（nonlinear），需要激活函数（activation function）。\n激活函数就是应用于每一层输出的函数，最常见的是rectifier函数$max(0,x).$\n把rectifier应用到一个线性单元上时，就得到了rectified linear unit，或简称ReLU。这样这个线性单元的输出就是$max(0,w\\cdot x+b)$\nStacking Dense Layers 堆叠层来获得复杂的数据转换： 输出层之前的层有时被称为隐藏层（hidden），因为我们没有直接看到它们的输出。上图在输出之前使用了一个线性单元，而不是激活函数，这样做使这个模型适用于回归任务，在分类任务中，可能要在这里使用激活函数。\nBuilding Sequential Models 我们将用Sequential模型来连接一系列的层，建立上图的模型，第一次获得输入，最后一层产生输出\nfrom tensorflow import keras from tensorflow.keras import layers model = keras.Sequential([ # ReLU 隐藏层 layers.Dense(units=4, activation='relu', input_shape=[2]), # 输入 layers.Dense(units=3, activation='relu'), # 线性输出层 layers.Dense(units=1), ]) 一定要把所有的图层放在一个列表中，比如[layer，layer，layer，...]。要添加激活函数层，只要设置activation参数即可，比如ReLU：activation='relu'\nStochastic Gradient Descent Introduction 前面两节讲了如何构建全连接的网络（fully-connected networks），新创建的网络中的权重都是随机的，这一节就开始介绍如何训练神经网络。\n训练模型中每条数据需要输入一些特征（features）和一个期望的输出目标（target），训练的过程会调整权重，使网络可以通过输入的特征计算出期望的目标。\n除了训练数据，还需要：\n“损失函数”，用来衡量网络预测结果的好坏。 “优化器”，可以告诉网络如何改变其权重。 The Loss Function 损失函数（loss function）测量target真实值和模型预测值之间的差异。不同的问题需要使用不同的损失函数，比如回归问题（regression problems）常用的损失函数就是平均绝对误差MAE（mean absolute error），MAE通过差的绝对值abs(y_true-y_pred)测量预测值y_pred与真实目标y_true的差异。 数据集上的总MAE，是所有这些差的绝对值的平均值。\n除了MAE之外，回归问题还有其他的损失函数：均方误差（mean-squared error，MSE）或Huber损失（Huber loss），它们都可以在Keras中使用。 在训练期间，模型将使用损失函数作为指导，以找到正确的权重值（loss越小越好）。换句话说，损失函数告诉网络它的目标。\nThe Optimizer - Stochastic Gradient Descent 随机梯度下降，这里的“随机”用的是stochastic，而非熟悉的random，查了一下维基百科：\nAlthough stochasticity and randomness are distinct in that the former refers to a modeling approach and the latter refers to phenomena themselves, these two terms are often used synonymously. Furthermore, in probability theory, the formal concept of a stochastic process is also referred to as a random process.\nstochastic 偏向指建模方法，random 偏向指现象本身，很多时候这两个词是同义的。\n优化器（optimizer）是一种调整权重来使loss最小化的算法。深度学习中使用的所有优化器算法都属于一个叫做随机梯度下降的家族，训练网络的过程就是一次次迭代下面的算法：\n采集一些训练数据，通过网络进行预测 测量预测值和真实值之间的损失 最后，调整权重使loss更小 使用随机梯度下降的神经网络\n每个迭代的训练数据样本称为一个minibatch（或称batch），而一轮完整的训练数据称为一个epoch。你训练的次数是网络看到每个训练示例的次数。网络看到每个训练示例的次数，就是训练的轮数。\n上面的动画显示了线性模型在使用SGD进行训练，淡红色的点是整个数据集，变化的实心红点表示minibatch，每次SGD看到一个新的minibatch，它都会将权重（w斜率，by轴截距）移向batch的正确值，经过一轮又一轮的batch，直线最终会收敛到最佳状态，可以看到，权重越接近真实值，loss就越小。\nLearning Rate and Batch Size 可以注意到直线每次会在batch的方向上发生一个小的移动，这个移动变化的大小取决于学习率（learning rate），学习率越小，在逼近正确值的过程就越长。\n学习率（Learning Rate）和batch的大小（Batch Size）是对SGD训练进度影响最大的两个参数。它们之间的相互作用往往很微妙，对这些参数的正确选择并不总是显而易见的。（我们将在练习中探讨这些影响）\n幸运的是，对于大多数工作来说，没有必要进行广泛的超参数搜索以获得满意的结果。Adam是一种SGD算法，具有自适应学习率，使其适用于大多数问题，而无需任何参数调整（从某种意义上说，它是“自调整”）。Adam是一个伟大的通用优化器。\nAdding the Loss and Optimizer 定义模型后，可以使用模型的compile方法添加损失函数和优化器：\nmodel.compile( optimizer=\"adam\", loss=\"mae\", ) 只需要一个字符串就可以指定loss和optimizer；也可以通过Keras API直接访问这些参数——例如想要优化参数——但对我们来说，默认值就可以正常工作。\n梯度（gradient）是一个向量，告诉我们权重应该朝哪个方向移动，也就是说它告诉我们如何改变重量使损失变化最快，我们称过程为梯度下降（descent），是因为它使用梯度将损失曲线下降到最小值，随机（stochastic）是指每次选取的minibatches是从训练数据中随机选取的随机样例。SGD即Stochastic Gradient Descent。\nfrom tensorflow import keras from tensorflow.keras import layers model = keras.Sequential([ layers.Dense(512, activation='relu', input_shape=[11]), layers.Dense(512, activation='relu'), layers.Dense(512, activation='relu'), layers.Dense(1), ]) # 给模型设置优化器和损失函数 model.compile( optimizer='adam', loss='mae', ) # 每轮给模型 256 行数据，这样训练 10 轮 history = model.fit( X_train, y_train, validation_data=(X_valid, y_valid), batch_size=256, epochs=10, ) 在每一轮的训练后，都会输出当前的loss，并且训练过程中的loss都会被保存起来，所以我们可以用它们作图来更直观的看出loss的变化：\nimport pandas as pd # convert the training history to a dataframe history_df = pd.DataFrame(history.history) # use Pandas native plot method history_df['loss'].plot(); loss的变化曲线逐渐变得趋于水平了，就说明模型已经学会了它能学会的一切，所以没有必要让它进行更多的迭代，如果想要优化loss，更应该做的是调整模型。\nOverfitting and Underfitting Interpreting the Learning Curves 模型得到的数据是由信息（signal）和噪声（noise）组成的，我们希望它从signal中学习到模式，这样可以使其在预测过程中表现良好，噪声是只在训练数据中正确的案例。\n下图绘制了在训练数据上和在测试数据上的loss情况，这些曲线我们称之为学习曲线（learning curves），为了有效的训练深度学习模型，我们需要能够解释它们。\n在模型学习signal和noise的过程中，训练loss会逐渐下降，但只有模型学习到signal时，验证loss才会降低。在学习signal的过程中，两条曲线都会下降，但是如果模型学习了noise，那么两条曲线之间就会出现空隙（gap），这个空隙的大小，可以反应模型学到了多少noise。理想情况下我们希望模型只学习signal不学习noise，但这几乎是不可能的，只能以学习到很多的noise为代价，让模型尽可能多的学习到signal，从上图可以看出，当出现了某一点后，验证loss会逐渐上升。\n在训练模型时可能会出现两个问题：\nsignal不足或噪声过大。未充分拟合训练集 是指由于模型没有学习到足够的signal，导致loss没有尽可能低。 过度拟合训练集是指由于模型学习了太多的噪声，导致loss没有尽可能低。 训练深度学习模型的诀窍是在两者之间找到最佳平衡，我们将研究几种从训练数据中获取更多signal的方法，同时减少噪声。\nCapacity 模型的容量是指它能够学习的模式的大小和复杂性，对于神经网络来说，这在很大程度上取决于它有多少神经元以及它们如何连接在一起。如果网络似乎不适合数据，应该尝试增加其容量。\n可以通过使网络更宽（将更多神经元添加到现有层）或使其更深（添加更多层）来增加网络的容量。更宽的网络更容易学习更多的线性关系，而更深的网络更喜欢非线性关系。哪个更好取决于数据集。\nmodel = keras.Sequential([ layers.Dense(16, activation='relu'), layers.Dense(1), ]) wider = keras.Sequential([ layers.Dense(32, activation='relu'), layers.Dense(1), ]) deeper = keras.Sequential([ layers.Dense(16, activation='relu'), layers.Dense(16, activation='relu'), layers.Dense(1), ]) Early Stopping 当模型学习到很多噪声时，验证损失可能会在训练期间开始增加，为了防止这种情况，只要验证loss似乎不再减少，我们就可以停止训练。以这种方式中断训练被称为提前停止（Early Stopping）。\n一旦检测到了验证loss再次上升，就可以将权重重置回之前loss最小值的位置，确保了模型不会继续过拟合。\nAdding Early Stopping 在Keras中，我们通过回调（callback）在训练中提前停止，回调函数是一个在网络运行时需要经常运行的函数。提前停止回调将在每个epoch之后运行。（Keras预先定义了各种有用的回调，也可以定义自己的回调。）\nfrom tensorflow.keras.callbacks import EarlyStopping early_stopping = EarlyStopping( min_delta=0.001, # minimium amount of change to count as an improvement patience=20, # 20个 restore_best_weights=True, ) 如果在过去20个epochs中，验证loss没有改善0.001，那么停止训练，保留找到的最佳模型。\nExample - Train a Model with Early Stopping from tensorflow import keras from tensorflow.keras import layers, callbacks early_stopping = callbacks.EarlyStopping( min_delta=0.001, # minimium amount of change to count as an improvement patience=20, # how many epochs to wait before stopping restore_best_weights=True, ) model = keras.Sequential([ layers.Dense(512, activation='relu', input_shape=[11]), layers.Dense(512, activation='relu'), layers.Dense(512, activation='relu'), layers.Dense(1), ]) model.compile( optimizer='adam', loss='mae', ) history = model.fit( X_train, y_train, validation_data=(X_valid, y_valid), batch_size=256, epochs=500, callbacks=[early_stopping], # put your callbacks in a list verbose=0, # turn off training log ) history_df = pd.DataFrame(history.history) history_df.loc[:, ['loss', 'val_loss']].plot(); print(\"Minimum validation loss: {}\".format(history_df['val_loss'].min())) Dropout and Batch Normalization keras有几十中layers，可以在 Keras docs 中查看示例。这一节将介绍两种特殊的layer，它们本身不包含神经元。\nDropout Dropout可以帮助修正overfitting。\n前面讲过了数据的欠拟合和过拟合，出现了过拟合的情况，是因为网络模型学习了训练数据中的虚假的模式（噪声的模式），模型为了学习到这个模式 通常会依赖非常特定的权重组合，所以这种权重的组合才实现出的模式，往往是很脆弱的，移除一个就会瓦解。\nDropout就是在训练的每一步都随机删除一层输入单元的一小部分，这使得网络更难从训练数据中学习这些虚假模式。相反，它必须寻找广泛的、一般的模式，其权重模式往往更稳健。\nAdding Dropout 在Keras中，dropout率参数rate定义了要关闭的输入单元的百分比。将Dropout layer放在要应用Dropout的层之前：\nkeras.Sequential([ # ... layers.Dropout(rate=0.3), # apply 30% dropout to the next layer layers.Dense(16), # ... ]) Batch Normalization “batch normalization\"或称\"batchnorm\"这个特殊层有助于纠正缓慢或不稳定的训练。在神经网络中通常需要将所有的数据放在一个通用的尺度上，可以使用scikit learn的StandardScaler或MinMaxScaler之类的工具，这是因为SGD根据数据产生的激活量按比例改变网络中的权重，训练中的数值大小范围不一样可能会导致不稳定的训练。\n可以在数据进入网络之前对其进行规范化（normalize），但是更好的操作是在网络的内部对数据进行规范化，batch normalization layer就是用来对网络中的数据进行规范化操作的，它会用其自身的平均值和标准差对batch进行标准化，然后用两个可训练的重缩放参数（trainable rescaling parameters）将数据放在一个新的尺度上。\n使用batchnorm的模型往往需要较少的时间完成训练，也可以解决可能导致训练“停滞”的各种问题，所以可以考虑在模型中添加batchnorm。\nAdding Batch Normalization batchnorm可以放在相对其他层的各种位置上，如果用它作为网络的第一层，就起到了一个代替预处理时对数据进行标准化的操作，类似Sci-Kit Learn的 StandardScaler，也可以放在某一层之后：\nlayers.Dense(16, activation='relu'), layers.BatchNormalization(), 或在某层和它的激活函数之间：\nlayers.Dense(16), layers.BatchNormalization(), layers.Activation('relu'), Example - Using Dropout and Batch Normalization 如果模型中使用了dropout，就应该在层中添加更多的单元，因为每次都会被随机抛弃一部分不参与的单元。\nfrom tensorflow import keras from tensorflow.keras import layers model = keras.Sequential([ layers.Dense(1024, activation='relu', input_shape=[11]), layers.Dropout(0.3), layers.BatchNormalization(), layers.Dense(1024, activation='relu'), layers.Dropout(0.3), layers.BatchNormalization(), layers.Dense(1024, activation='relu'), layers.Dropout(0.3), layers.BatchNormalization(), layers.Dense(1), ]) model.compile( optimizer='adam', loss='mae', ) history = model.fit( X_train, y_train, validation_data=(X_valid, y_valid), batch_size=256, epochs=100, verbose=0, ) # Show the learning curves history_df = pd.DataFrame(history.history) history_df.loc[:, ['loss', 'val_loss']].plot(); Binary Classification Introduction 之前的部分在介绍用深度学习解决回归问题，这一节介绍用深度学习解决分类问题。\nBinary Classification 二分类问题是指分成两类的问题，比如用\"Yes”/“No\"来回答的问题。我们需要给数据class label：0 或 1，数字标签是神经网络模型可以使用的数据形式。\nAccuracy and Cross-Entropy 准确性（Accuracy）是衡量分类问题成功与否的众多指标之一。accuracy是正确预测与总预测的比率：accuracy = number_correct / total。一个总是正确预测的模型的准确度得分为1.0。在所有其他条件相同的情况下，每当数据集中的类以大约相同的频率出现时，准确度是一个合理的指标。\naccuracy（以及大多数其他分类指标）的问题在于，它不能用作损失函数。SGD需要一个平稳变化的损失函数，但精度，作为计数的比率，在“跳跃”中变化。因此，我们必须选择一个替代品作为损失函数。这个替代品是交叉熵函数（cross-entropy function）。\n现在，回想一下损失函数定义了训练期间网络的目标。通过回归，我们的目标是最小化预期结果和预测结果之间的距离。我们选择了MAE来测量这个距离。\n对于分类，我们想要的是概率之间的距离，这就是交叉熵提供的。Cross-entropy是一种度量从一个概率分布到另一个概率分布的距离的方法。\n我们希望我们的网络以1.0的概率预测正确的班级。预测概率离1.0越远，交叉熵损失越大。\n我们使用交叉熵的技术原因有点微妙，但从这一节中我们要了解的主要内容是：使用交叉熵来进行分类损失；你可能关心的其他指标（如准确性）也会随之提高。\nMaking Probabilities with the Sigmoid Function 交叉熵和精度函数都需要概率作为输入，即0到1之间的数字。为了将密集层产生的实值输出转化为概率，我们附加了一种新的激活函数，即sigmoid激活函数。\n为了得到最终的类预测，我们定义了一个阈值概率。通常这将是0.5，因此四舍五入将为我们提供正确的类别：低于0.5表示标签为0的类别，0.5或以上表示标签为1的类别。0.5阈值是Keras默认使用的精度指标。\nExample - Binary Classification 除了最后一层用了“sigmoid”激活，它用来产生类概率，其他部分和回归任务一样。\nfrom tensorflow import keras from tensorflow.keras import layers model = keras.Sequential([ layers.Dense(4, activation='relu', input_shape=[33]), layers.Dense(4, activation='relu'), layers.Dense(1, activation='sigmoid'), ]) model.compile( optimizer='adam', # Adam也适用于分类问题 loss='binary_crossentropy', # 损失函数为 交叉熵函数 metrics=['binary_accuracy'], ) # 提前停止 回调函数 early_stopping = keras.callbacks.EarlyStopping( patience=10, min_delta=0.001, restore_best_weights=True, ) history = model.fit( X_train, y_train, validation_data=(X_valid, y_valid), batch_size=512, epochs=1000, callbacks=[early_stopping], verbose=0, # hide the output because we have so many epochs ) history_df = pd.DataFrame(history.history) # Start the plot at epoch 5 history_df.loc[5:, ['loss', 'val_loss']].plot() history_df.loc[5:, ['binary_accuracy', 'val_binary_accuracy']].plot() print((\"Best Validation Loss: {:0.4f}\" +\\ \"\\nBest Validation Accuracy: {:0.4f}\")\\ .format(history_df['val_loss'].min(), history_df['val_binary_accuracy'].max())) Best Validation Loss: 0.5482 Best Validation Accuracy: 0.7619 Detecting the Higgs Boson With TPUs 这是属于Intro to Deep Learning的一节Bonus Lesson，介绍如何使用TPU的。\n# TensorFlow import tensorflow as tf print(\"Tensorflow version \" + tf.__version__) # Detect and init the TPU try: # detect TPUs tpu = tf.distribute.cluster_resolver.TPUClusterResolver.connect() # TPU detection strategy = tf.distribute.TPUStrategy(tpu) except ValueError: # detect GPUs strategy = tf.distribute.get_strategy() # default strategy that works on CPU and single GPU print(\"Number of accelerators: \", strategy.num_replicas_in_sync) Computer Vision The Convolutional Classifier Introduction 卷积神经网络（convolutional neural networks）是最擅长理解图像的神经网络，我们称之为convent或CNN。卷积是一种数学运算，它使网络的各层具有独特的结构。\nThe Convolutional Classifier 用于图像分类的convnet由两部分组成：convolutional base 和 dense head。\nBase用于从图像中提取特征，它主要由执行卷积运算的层组成，但通常也包括其他类型的层。 Head用于确定图像的类别，它主要由致密层构成，但也可能包括其他层，如脱落层。 特征可以是线条、颜色、纹理、形状、图案，也可以是一些复杂的组合。\nTraining the Classifier 训练期间网络的目标是学习两件事：\n要从图像中提取哪些特征 (base)， 哪一类与哪些特征相匹配 (head)。 如今，convnet很少从零开始训练。更常见的情况是，我们重用预训练模型的基础。然后，我们在预先训练好的Base加上一个未经训练的Head。换句话说，我们重用网络中已经学会做提取特征的层，并附加一些新的层来学习分类。\n因为头部通常只有几个密集的层，所以可以从相对较少的数据中创建非常精确的分类器。\n迁移学习就是一种重用预先训练好的模型的技术。它非常有效，现在几乎所有的图像分类器都会使用它。\nExample - Train a Convnet Classifier 我们将创建一个用于分类汽车和卡车的分类器，数据集是大约10000张图片，其中汽车和卡车的几乎各占一半。\nStep 1 - Load Data # 导入一些包 import os, warnings import matplotlib.pyplot as plt from matplotlib import gridspec import numpy as np import tensorflow as tf from tensorflow.keras.preprocessing import image_dataset_from_directory # 设置固定的种子，来保证可复现性 def set_seed(seed=31415): np.random.seed(seed) tf.random.set_seed(seed) os.environ['PYTHONHASHSEED'] = str(seed) os.environ['TF_DETERMINISTIC_OPS'] = '1' set_seed(31415) # 设置 Matplotlib 的默认值 plt.rc('figure', autolayout=True) plt.rc('axes', labelweight='bold', labelsize='large', titleweight='bold', titlesize=18, titlepad=10) plt.rc('image', cmap='magma') warnings.filterwarnings(\"ignore\") # to clean up output cells # Load training and validation sets ds_train_ = image_dataset_from_directory( '../input/car-or-truck/train', # 文件夹 labels='inferred', label_mode='binary', image_size=[128, 128], # 图片大小 interpolation='nearest', batch_size=64, shuffle=True, ) ds_valid_ = image_dataset_from_directory( '../input/car-or-truck/valid', labels='inferred', label_mode='binary', image_size=[128, 128], interpolation='nearest', batch_size=64, shuffle=False, ) # Data Pipeline def convert_to_float(image, label): image = tf.image.convert_image_dtype(image, dtype=tf.float32) return image, label AUTOTUNE = tf.data.experimental.AUTOTUNE ds_train = ( ds_train_ .map(convert_to_float) .cache() .prefetch(buffer_size=AUTOTUNE) ) ds_valid = ( ds_valid_ .map(convert_to_float) .cache() .prefetch(buffer_size=AUTOTUNE) ) Step 2 - Define Pretrained Base 最常用的预训练数据集是ImageNet，这是一个包含多种自然图像的大型数据集。Keras在其 applications模块中包含在ImageNet上预训练的各种模型。我们将使用的预训练模型称为VGG16。\npretrained_base = tf.keras.models.load_model( '../input/cv-course-models/cv-course-models/vgg16-pretrained-base', ) pretrained_base.trainable = False VGG16也可以这样直接调用：\ntf.keras.applications.vgg16.VGG16( include_top=True, weights='imagenet', input_tensor=None, input_shape=None, pooling=None, classes=1000, classifier_activation='softmax' ) Step 3 - Attach Head 接下来连接分类器head。先用一个Flatten层，把前面二维的输出转化为一维来提供给后面的层。然后是一个隐藏层，最后一层（输出层）把输出转换为判断是Truck的概率分数。\nfrom tensorflow import keras from tensorflow.keras import layers model = keras.Sequential([ pretrained_base, layers.Flatten(), layers.Dense(6, activation='relu'), layers.Dense(1, activation='sigmoid'), ]) Step 4 - Train 由于这是一个分成两类的问题，所以我们使用二进制版本的crossentropy和accuracy。\nmodel.compile( optimizer='adam', loss='binary_crossentropy', # 损失函数 metrics=['binary_accuracy'], # 准确度评估 ) history = model.fit( ds_train, validation_data=ds_valid, epochs=30, verbose=0, ) 在训练神经网络模型时，最好检查loss和metric曲线，变化过程被存储在history.history中，可以这样把它们显示出来：\nimport pandas as pd history_frame = pd.DataFrame(history.history) history_frame.loc[:, ['loss', 'val_loss']].plot() history_frame.loc[:, ['binary_accuracy', 'val_binary_accuracy']].plot(); Convolution and ReLU 前一节我们了解到卷积分类器有两部分：base和head，base从图像中提取特征，head使用这些特征对图像分类。\n后面的几节教程会介绍base部分 最重要的两种类型的层，它们分别是：具有ReLU激活的卷积层 和 最大池化层。第5节教程将会介绍通过这些层的组合来进行特征提取（Base部分）。\n这一节是关于卷积层和ReLU激活函数的。\nFeature Extraction 由base执行的特征提取包括三个基本操作：\n针对特定特征过滤（filter）图像（卷积） 在过滤后的图像中检测（detect）该特征（ReLU） 压缩（condense）图像以增强特征（最大池化） 下图说明了这个过程，可以看到这三个操作是如何隔离原始图像的某些特定特征的（在本例中为水平线）。\n通常网络会在一个图片上并行的提取，在一些现代的convnets中，最后一层产生1000多个独特的视觉特征也很多见。\nFilter with Convolution 卷积层执行滤波步骤,可以在Keras模型中定义一个卷积层：\nfrom tensorflow import keras from tensorflow.keras import layers model = keras.Sequential([ layers.Conv2D(filters=64, kernel_size=3), # activation is None # More layers follow ]) 我们可以通过观察这些参数与层的权重和激活的关系来理解这些参数。\nWeights convnet在训练期间学习的权重主要包含在其卷积层中，这些权重我们称之为核（kernels），我们可以将它们表示为小数组：\nkernel通过扫描图像并产生像素值的加权和来运行。通过这种方式，内核将像偏振光透镜一样，强调或不强调某些信息模式。\nKernels定义了卷积层如何连接到后面的层，上图中的kernel将前一层的9个神经元的输出，加权求和得到一个值输入到了后面层的一个神经元。我们可以使用kernel_size来设置kernel的维度，大多数情况下，kernel的维数都是奇数，如(3, 3)，(5, 5)，因此只有一个像素位于中心，但这并不是必须的。\n卷积层的kernel决定了它创建的特征类型，在训练期间，convent会尝试解决当前分类问题所需要的特征，这也意味着kernel的最佳取值。\nActivations 网络中的激活（activation），我们称之为特征映射（feature maps），它们是我们对图像应用过滤器时的结果；它们包含kernel提取的视觉特征。下面是一些kernel及其生成的特征映射：\n从kernel中的数字的模式，可以看出它创建的特征映射的类型。通常，卷积在其输入中强调的内容将与内核中正数的形状相匹配。上面的左核和中核都将过滤水平形状。\n使用filters参数，可以告诉卷积层希望它创建多少个特征贴图作为输出。\n",
  "wordCount" : "1084",
  "inLanguage": "en",
  "datePublished": "2022-03-12T16:23:00Z",
  "dateModified": "2022-03-12T16:23:00Z",
  "author":{
    "@type": "Person",
    "name": "Slightwind"
  },
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://blog.slightwind.cn/posts/tutorial/notes-kaggle-courses-intro-to-dl/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "Slightwind",
    "logo": {
      "@type": "ImageObject",
      "url": "https://blog.slightwind.cn/favicon.ico"
    }
  }
}
</script>
</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="https://blog.slightwind.cn/" accesskey="h" title="Slightwind (Alt + H)">Slightwind</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="https://blog.slightwind.cn/archives" title="Archive">
                    <span>Archive</span>
                </a>
            </li>
            <li>
                <a href="https://blog.slightwind.cn/search/" title="Search (Alt &#43; /)" accesskey=/>
                    <span>Search</span>
                </a>
            </li>
            <li>
                <a href="https://blog.slightwind.cn/tags/" title="Tags">
                    <span>Tags</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    <div class="breadcrumbs"><a href="https://blog.slightwind.cn/">Home</a>&nbsp;»&nbsp;<a href="https://blog.slightwind.cn/posts/">Posts</a></div>
    <h1 class="post-title">
      Notes: Kaggle Courses - Intro to DL &amp; Computer Vision
    </h1>
    <div class="post-meta"><span title='2022-03-12 16:23:00 +0000 UTC'>March 12, 2022</span>&nbsp;·&nbsp;6 min&nbsp;·&nbsp;Slightwind

</div>
  </header> <div class="toc">
    <details >
        <summary accesskey="c" title="(Alt + C)">
            <span class="details">Table of Contents</span>
        </summary>

        <div class="inner"><ul>
                <li>
                    <a href="#intro-to-deep-learning" aria-label="Intro to Deep Learning">Intro to Deep Learning</a><ul>
                        
                <li>
                    <a href="#a-single-neuron" aria-label="A Single Neuron">A Single Neuron</a><ul>
                        
                <li>
                    <a href="#the-linear-unit" aria-label="The Linear Unit">The Linear Unit</a></li>
                <li>
                    <a href="#example---the-linear-unit-as-a-model" aria-label="Example - The Linear Unit as a Model">Example - The Linear Unit as a Model</a></li>
                <li>
                    <a href="#multiple-inputs" aria-label="Multiple Inputs">Multiple Inputs</a></li>
                <li>
                    <a href="#linear-units-in-keras" aria-label="Linear Units in Keras">Linear Units in Keras</a></li></ul>
                </li>
                <li>
                    <a href="#deep-neural-networks" aria-label="Deep Neural Networks">Deep Neural Networks</a><ul>
                        
                <li>
                    <a href="#layers" aria-label="Layers">Layers</a></li>
                <li>
                    <a href="#the-activation-function" aria-label="The Activation Function">The Activation Function</a></li>
                <li>
                    <a href="#stacking-dense-layers" aria-label="Stacking Dense Layers">Stacking Dense Layers</a><ul>
                        
                <li>
                    <a href="#building-sequential-models" aria-label="Building Sequential Models">Building Sequential Models</a></li></ul>
                </li></ul>
                </li>
                <li>
                    <a href="#stochastic-gradient-descent" aria-label="Stochastic Gradient Descent">Stochastic Gradient Descent</a><ul>
                        
                <li>
                    <a href="#introduction" aria-label="Introduction">Introduction</a></li>
                <li>
                    <a href="#the-loss-function" aria-label="The Loss Function">The Loss Function</a></li>
                <li>
                    <a href="#the-optimizer---stochastic-gradient-descent" aria-label="The Optimizer - Stochastic Gradient Descent">The Optimizer - Stochastic Gradient Descent</a></li>
                <li>
                    <a href="#learning-rate-and-batch-size" aria-label="Learning Rate and Batch Size">Learning Rate and Batch Size</a></li>
                <li>
                    <a href="#adding-the-loss-and-optimizer" aria-label="Adding the Loss and Optimizer">Adding the Loss and Optimizer</a></li></ul>
                </li>
                <li>
                    <a href="#overfitting-and-underfitting" aria-label="Overfitting and Underfitting">Overfitting and Underfitting</a><ul>
                        
                <li>
                    <a href="#interpreting-the-learning-curves" aria-label="Interpreting the Learning Curves">Interpreting the Learning Curves</a></li>
                <li>
                    <a href="#capacity" aria-label="Capacity">Capacity</a></li>
                <li>
                    <a href="#early-stopping" aria-label="Early Stopping">Early Stopping</a></li>
                <li>
                    <a href="#adding-early-stopping" aria-label="Adding Early Stopping">Adding Early Stopping</a></li>
                <li>
                    <a href="#example---train-a-model-with-early-stopping" aria-label="Example - Train a Model with Early Stopping">Example - Train a Model with Early Stopping</a></li></ul>
                </li>
                <li>
                    <a href="#dropout-and-batch-normalization" aria-label="Dropout and Batch Normalization">Dropout and Batch Normalization</a><ul>
                        
                <li>
                    <a href="#dropout" aria-label="Dropout">Dropout</a></li>
                <li>
                    <a href="#adding-dropout" aria-label="Adding Dropout">Adding Dropout</a></li>
                <li>
                    <a href="#batch-normalization" aria-label="Batch Normalization">Batch Normalization</a></li>
                <li>
                    <a href="#adding-batch-normalization" aria-label="Adding Batch Normalization">Adding Batch Normalization</a></li>
                <li>
                    <a href="#example---using-dropout-and-batch-normalization" aria-label="Example - Using Dropout and Batch Normalization">Example - Using Dropout and Batch Normalization</a></li></ul>
                </li>
                <li>
                    <a href="#binary-classification" aria-label="Binary Classification">Binary Classification</a><ul>
                        
                <li>
                    <a href="#introduction-1" aria-label="Introduction">Introduction</a></li>
                <li>
                    <a href="#binary-classification-1" aria-label="Binary Classification">Binary Classification</a></li>
                <li>
                    <a href="#accuracy-and-cross-entropy" aria-label="Accuracy and Cross-Entropy">Accuracy and Cross-Entropy</a></li>
                <li>
                    <a href="#making-probabilities-with-the-sigmoid-function" aria-label="Making Probabilities with the Sigmoid Function">Making Probabilities with the Sigmoid Function</a></li>
                <li>
                    <a href="#example---binary-classification" aria-label="Example - Binary Classification">Example - Binary Classification</a></li></ul>
                </li>
                <li>
                    <a href="#detecting-the-higgs-boson-with-tpus" aria-label="Detecting the Higgs Boson With TPUs">Detecting the Higgs Boson With TPUs</a></li></ul>
                </li>
                <li>
                    <a href="#computer-vision" aria-label="Computer Vision">Computer Vision</a><ul>
                        
                <li>
                    <a href="#the-convolutional-classifier" aria-label="The Convolutional Classifier">The Convolutional Classifier</a><ul>
                        
                <li>
                    <a href="#introduction-2" aria-label="Introduction">Introduction</a></li>
                <li>
                    <a href="#the-convolutional-classifier-1" aria-label="The Convolutional Classifier">The Convolutional Classifier</a></li>
                <li>
                    <a href="#training-the-classifier" aria-label="Training the Classifier">Training the Classifier</a></li>
                <li>
                    <a href="#example---train-a-convnet-classifier" aria-label="Example - Train a Convnet Classifier">Example - Train a Convnet Classifier</a><ul>
                        
                <li>
                    <a href="#step-1---load-data" aria-label="Step 1 - Load Data">Step 1 - Load Data</a></li>
                <li>
                    <a href="#step-2---define-pretrained-base" aria-label="Step 2 - Define Pretrained Base">Step 2 - Define Pretrained Base</a></li>
                <li>
                    <a href="#step-3---attach-head" aria-label="Step 3 - Attach Head">Step 3 - Attach Head</a></li>
                <li>
                    <a href="#step-4---train" aria-label="Step 4 - Train">Step 4 - Train</a></li></ul>
                </li></ul>
                </li>
                <li>
                    <a href="#convolution-and-relu" aria-label="Convolution and ReLU">Convolution and ReLU</a><ul>
                        
                <li>
                    <a href="#feature-extraction" aria-label="Feature Extraction">Feature Extraction</a></li>
                <li>
                    <a href="#filter-with-convolution" aria-label="Filter with Convolution">Filter with Convolution</a><ul>
                        
                <li>
                    <a href="#weights" aria-label="Weights">Weights</a></li></ul>
                </li>
                <li>
                    <a href="#activations" aria-label="Activations">Activations</a>
                </li>
            </ul>
            </li>
            </ul>
            </li>
            </ul>
        </div>
    </details>
</div>

  <div class="post-content"><h1 id="intro-to-deep-learning">Intro to Deep Learning<a hidden class="anchor" aria-hidden="true" href="#intro-to-deep-learning">#</a></h1>
<h2 id="a-single-neuron">A Single Neuron<a hidden class="anchor" aria-hidden="true" href="#a-single-neuron">#</a></h2>
<h3 id="the-linear-unit">The Linear Unit<a hidden class="anchor" aria-hidden="true" href="#the-linear-unit">#</a></h3>
<p>下面是一个<strong>neuron</strong>（或称<strong>unit</strong>）的示意图，<code>x</code>是输入；<code>w</code>是x的权重<strong>weight</strong>；<code>b</code>是<strong>bias</strong>，是一种特殊的权重，没有和bias相关的输入数据，它可以独立于输入修改输出。神经网络通过修改权重来“learn”。</p>
<p><code>y</code>是这个神经元输出的值，$y=wx+b$，刚好是一个直线的方程，w是斜率，b是在y轴上的截距。</p>
<p>
<img loading="lazy" src="https://s1.ax1x.com/2022/03/26/qUYHYt.png" alt="The Linear Unit: 𝑦=𝑤𝑥&#43;𝑏"   /></p>
<h3 id="example---the-linear-unit-as-a-model">Example - The Linear Unit as a Model<a hidden class="anchor" aria-hidden="true" href="#example---the-linear-unit-as-a-model">#</a></h3>
<p>单个神经元是通常只会在更大的网络中发挥作用，单神经元模型是线性模型。当$w=2.5, b=90$时，这个线性模型可以用来反应糖<code>'sugars'</code>和卡路里<code>'calories'</code>的关系：</p>
<p>
<img loading="lazy" src="https://s1.ax1x.com/2022/03/26/qUNhad.png" alt="&lt;em&gt;Computing with the linear unit.&lt;/em&gt;"   /></p>
<h3 id="multiple-inputs">Multiple Inputs<a hidden class="anchor" aria-hidden="true" href="#multiple-inputs">#</a></h3>
<p>对于多个输入，也是这样将每个输入乘以权重，并把它们相加。下面这个对应的公式为：$y=w_{0} x_{0}+w_{1} x_{1}+w_{2} x_{2}+b.$

<img loading="lazy" src="https://s1.ax1x.com/2022/03/26/qUtCYq.png" alt="A linear unit with three inputs."   /></p>
<h3 id="linear-units-in-keras">Linear Units in Keras<a hidden class="anchor" aria-hidden="true" href="#linear-units-in-keras">#</a></h3>
<p>在Keras中创建模型最简单的方法是使用<code>keras.Sequential</code>，下面这个示例表示一个线性模型，可以输入3个特征（&lsquo;sugars&rsquo;, &lsquo;fiber&rsquo;, &lsquo;protein&rsquo;），并且只有一个输出：&lsquo;calories&rsquo;。</p>
<pre><code class="language-python">from tensorflow import keras
from tensorflow.keras import layers

# Create a network with 1 linear unit
model = keras.Sequential([
    layers.Dense(units=1, input_shape=[3])
])
</code></pre>
<p>第一个参数units定义输出的个数，input_shape告诉Keras输入特征的数量。目前只需要用到<code>input_shape=[num_columns]</code>，input_shape还可以支持使用更复杂的数据：<code>[height, width, channels]</code>。</p>
<p><code>Tensors</code>是TensorFlow版本的numpy数组，并且做了一些使它更适合用于机器学习的改变，Tensors与GPU/TPU加速器兼容，而TPU就是专为Tensors而设计的。在Keras内部，使用Tensors表示神经网络的权重。</p>
<p><code>model.weights</code>可以用来查看权重，在训练开始前，权重都会被初始化为随机值。</p>
<h2 id="deep-neural-networks">Deep Neural Networks<a hidden class="anchor" aria-hidden="true" href="#deep-neural-networks">#</a></h2>
<h3 id="layers">Layers<a hidden class="anchor" aria-hidden="true" href="#layers">#</a></h3>
<p>神经网络会将神经元组成<strong>层（layers）</strong>，合并有相同的输入的线性神经元，就得到了一个<strong>稠密层（dense layer）</strong>

<img loading="lazy" src="https://s1.ax1x.com/2022/03/26/qUY0L4.png" alt="A dense layer of two linear units receiving two inputs and a bias."   /></p>
<h3 id="the-activation-function">The Activation Function<a hidden class="anchor" aria-hidden="true" href="#the-activation-function">#</a></h3>
<p>两个中间没有其他东西的稠密层，效果并不会比一个稠密层的效果好多少，“稠密层本身不能带我们离开线和面的世界”，我们需要的是非线性（nonlinear），需要激活函数（activation function）。</p>
<p>
<img loading="lazy" src="https://s1.ax1x.com/2022/03/26/qUYbfP.png" alt="没有激活函数，模型只能学习线性关系，为了拟合曲线，需要使用激活函数"   /></p>
<p>激活函数就是应用于每一层输出的函数，最常见的是<em>rectifier</em>函数$max(0,x).$</p>
<p>
<img loading="lazy" src="https://s1.ax1x.com/2022/03/26/qUYsoR.png" alt=""   /></p>
<p>把rectifier应用到一个线性单元上时，就得到了<strong>rectified linear unit</strong>，或简称<strong>ReLU</strong>。这样这个线性单元的输出就是$max(0,w\cdot x+b)$</p>
<p>
<img loading="lazy" src="https://s1.ax1x.com/2022/03/26/qUY5eH.png" alt=""   /></p>
<h3 id="stacking-dense-layers">Stacking Dense Layers<a hidden class="anchor" aria-hidden="true" href="#stacking-dense-layers">#</a></h3>
<p>堆叠层来获得复杂的数据转换：

<img loading="lazy" src="https://s1.ax1x.com/2022/03/26/qUtFpV.png" alt="A stack of dense layers makes a &amp;ldquo;fully-connected&amp;rdquo; network."   /></p>
<p>输出层之前的层有时被称为<strong>隐藏层（hidden）</strong>，因为我们没有直接看到它们的输出。上图在输出之前使用了一个线性单元，而不是激活函数，这样做使这个模型适用于回归任务，在分类任务中，可能要在这里使用激活函数。</p>
<h4 id="building-sequential-models">Building Sequential Models<a hidden class="anchor" aria-hidden="true" href="#building-sequential-models">#</a></h4>
<p>我们将用<code>Sequential</code>模型来连接一系列的层，建立上图的模型，第一次获得输入，最后一层产生输出</p>
<pre><code class="language-python">from tensorflow import keras
from tensorflow.keras import layers

model = keras.Sequential([
    # ReLU 隐藏层
    layers.Dense(units=4, activation='relu', input_shape=[2]), # 输入
    layers.Dense(units=3, activation='relu'),
    # 线性输出层
    layers.Dense(units=1),
])
</code></pre>
<p>一定要把所有的图层放在一个列表中，比如<code>[layer，layer，layer，...]</code>。要添加激活函数层，只要设置<code>activation</code>参数即可，比如ReLU：<code>activation='relu'</code></p>
<h2 id="stochastic-gradient-descent">Stochastic Gradient Descent<a hidden class="anchor" aria-hidden="true" href="#stochastic-gradient-descent">#</a></h2>
<h3 id="introduction">Introduction<a hidden class="anchor" aria-hidden="true" href="#introduction">#</a></h3>
<p>前面两节讲了如何构建全连接的网络（fully-connected networks），新创建的网络中的权重都是随机的，这一节就开始介绍如何训练神经网络。</p>
<p>训练模型中每条数据需要输入一些特征（features）和一个期望的输出目标（target），训练的过程会调整权重，使网络可以通过输入的特征计算出期望的目标。</p>
<p>除了训练数据，还需要：</p>
<ul>
<li>“损失函数”，用来衡量网络预测结果的好坏。</li>
<li>“优化器”，可以告诉网络如何改变其权重。</li>
</ul>
<h3 id="the-loss-function">The Loss Function<a hidden class="anchor" aria-hidden="true" href="#the-loss-function">#</a></h3>
<p><strong>损失函数</strong>（loss function）测量target真实值和模型预测值之间的差异。不同的问题需要使用不同的损失函数，比如<strong>回归问题</strong>（regression problems）常用的损失函数就是平均绝对误差<strong>MAE</strong>（mean absolute error），MAE通过差的绝对值<code>abs(y_true-y_pred)</code>测量预测值<code>y_pred</code>与真实目标<code>y_true</code>的差异。
数据集上的总MAE，是所有这些差的绝对值的平均值。</p>
<p>
<img loading="lazy" src="https://s1.ax1x.com/2022/03/26/qUtSTs.png" alt="平均绝对误差是拟合曲线和数据点之间的平均长度"   /></p>
<p>除了MAE之外，回归问题还有其他的损失函数：均方误差（mean-squared error，MSE）或Huber损失（Huber loss），它们都可以在Keras中使用。
在训练期间，模型将使用损失函数作为指导，以找到正确的权重值（loss越小越好）。换句话说，损失函数告诉网络它的目标。</p>
<h3 id="the-optimizer---stochastic-gradient-descent">The Optimizer - Stochastic Gradient Descent<a hidden class="anchor" aria-hidden="true" href="#the-optimizer---stochastic-gradient-descent">#</a></h3>
<blockquote>
<p>随机梯度下降，这里的“随机”用的是stochastic，而非熟悉的random，查了一下维基百科：</p>
<blockquote>
<p>Although stochasticity and randomness are distinct in that the former refers to a modeling approach and the latter refers to phenomena themselves, these two terms are often used synonymously. Furthermore, in probability theory, the formal concept of a stochastic process is also referred to as a random process.</p>
</blockquote>
</blockquote>
<blockquote>
<p>stochastic 偏向指建模方法，random 偏向指现象本身，很多时候这两个词是同义的。</p>
</blockquote>
<p><strong>优化器</strong>（optimizer）是一种调整权重来使loss最小化的算法。深度学习中使用的所有优化器算法都属于一个叫做随机梯度下降的家族，训练网络的过程就是一次次迭代下面的算法：</p>
<ol>
<li>采集一些训练数据，通过网络进行预测</li>
<li>测量预测值和真实值之间的损失</li>
<li>最后，调整权重使loss更小</li>
</ol>
<img src="https://images.slightwind.cn/blog/kaggle/rFI1tIk.gif">
<p class="image-caption">使用随机梯度下降的神经网络</p>
<p>每个迭代的训练数据样本称为一个<strong>minibatch</strong>（或称<strong>batch</strong>），而一轮完整的训练数据称为一个<strong>epoch</strong>。你训练的次数是网络看到每个训练示例的次数。网络看到每个训练示例的次数，就是训练的轮数。</p>
<p>上面的动画显示了线性模型在使用SGD进行训练，淡红色的点是整个数据集，变化的实心红点表示minibatch，每次SGD看到一个新的minibatch，它都会将权重（<code>w</code>斜率，<code>b</code>y轴截距）移向batch的正确值，经过一轮又一轮的batch，直线最终会收敛到最佳状态，可以看到，权重越接近真实值，loss就越小。</p>
<h3 id="learning-rate-and-batch-size">Learning Rate and Batch Size<a hidden class="anchor" aria-hidden="true" href="#learning-rate-and-batch-size">#</a></h3>
<p>可以注意到直线每次会在batch的方向上发生一个小的移动，这个移动变化的大小取决于<strong>学习率</strong>（learning rate），学习率越小，在逼近正确值的过程就越长。</p>
<p>学习率（Learning Rate）和batch的大小（Batch Size）是对SGD训练进度影响最大的两个参数。它们之间的相互作用往往很微妙，对这些参数的正确选择并不总是显而易见的。（我们将在练习中探讨这些影响）</p>
<p>幸运的是，对于大多数工作来说，没有必要进行广泛的超参数搜索以获得满意的结果。Adam是一种SGD算法，具有自适应学习率，使其适用于大多数问题，而无需任何参数调整（从某种意义上说，它是“自调整”）。Adam是一个伟大的通用优化器。</p>
<h3 id="adding-the-loss-and-optimizer">Adding the Loss and Optimizer<a hidden class="anchor" aria-hidden="true" href="#adding-the-loss-and-optimizer">#</a></h3>
<p>定义模型后，可以使用模型的<code>compile</code>方法添加损失函数和优化器：</p>
<pre><code class="language-python">model.compile(
    optimizer=&quot;adam&quot;,
    loss=&quot;mae&quot;,
)
</code></pre>
<p>只需要一个字符串就可以指定loss和optimizer；也可以通过Keras API直接访问这些参数——例如想要优化参数——但对我们来说，默认值就可以正常工作。</p>
<p>梯度（<strong>gradient</strong>）是一个向量，告诉我们权重应该朝哪个方向移动，也就是说它告诉我们如何改变重量使损失变化最快，我们称过程为梯度下降（<strong>descent</strong>），是因为它使用梯度将损失曲线下降到最小值，随机（<strong>stochastic</strong>）是指每次选取的minibatches是从训练数据中随机选取的随机样例。SGD即Stochastic Gradient Descent。</p>
<pre><code class="language-python">from tensorflow import keras
from tensorflow.keras import layers

model = keras.Sequential([
    layers.Dense(512, activation='relu', input_shape=[11]),
    layers.Dense(512, activation='relu'),
    layers.Dense(512, activation='relu'),
    layers.Dense(1),
])

# 给模型设置优化器和损失函数
model.compile(
    optimizer='adam',
    loss='mae',
)

# 每轮给模型 256 行数据，这样训练 10 轮
history = model.fit(
    X_train, y_train,
    validation_data=(X_valid, y_valid),
    batch_size=256,
    epochs=10,
)
</code></pre>
<p>在每一轮的训练后，都会输出当前的loss，并且训练过程中的loss都会被保存起来，所以我们可以用它们作图来更直观的看出loss的变化：</p>
<pre><code class="language-python">import pandas as pd

# convert the training history to a dataframe
history_df = pd.DataFrame(history.history)
# use Pandas native plot method
history_df['loss'].plot();
</code></pre>
<p>
<img loading="lazy" src="https://s1.ax1x.com/2022/03/26/qUYdQU.png" alt=""   /></p>
<p>loss的变化曲线逐渐变得趋于水平了，就说明模型已经学会了它能学会的一切，所以没有必要让它进行更多的迭代，如果想要优化loss，更应该做的是调整模型。</p>
<h2 id="overfitting-and-underfitting">Overfitting and Underfitting<a hidden class="anchor" aria-hidden="true" href="#overfitting-and-underfitting">#</a></h2>
<h3 id="interpreting-the-learning-curves">Interpreting the Learning Curves<a hidden class="anchor" aria-hidden="true" href="#interpreting-the-learning-curves">#</a></h3>
<p>模型得到的数据是由<strong>信息</strong>（signal）和<strong>噪声</strong>（noise）组成的，我们希望它从signal中学习到模式，这样可以使其在预测过程中表现良好，噪声是只在训练数据中正确的案例。</p>
<p>下图绘制了在训练数据上和在测试数据上的loss情况，这些曲线我们称之为<strong>学习曲线</strong>（learning curves），为了有效的训练深度学习模型，我们需要能够解释它们。</p>
<p>
<img loading="lazy" src="https://s1.ax1x.com/2022/03/26/qUYxmQ.png" alt="The validation loss gives an estimate of the expected error on unseen data."   /></p>
<p>在模型学习signal和noise的过程中，训练loss会逐渐下降，但只有模型学习到signal时，验证loss才会降低。在学习signal的过程中，两条曲线都会下降，但是如果模型学习了noise，那么两条曲线之间就会出现空隙（gap），这个空隙的大小，可以反应模型学到了多少noise。理想情况下我们希望模型只学习signal不学习noise，但这几乎是不可能的，只能以学习到很多的noise为代价，让模型尽可能多的学习到signal，从上图可以看出，当出现了某一点后，验证loss会逐渐上升。</p>
<p>
<img loading="lazy" src="https://s1.ax1x.com/2022/03/26/qUYoTA.png" alt="Underfitting and overfitting."   /></p>
<p>在训练模型时可能会出现两个问题：</p>
<ol>
<li>signal不足或噪声过大。未充分拟合训练集 是指由于模型没有学习到足够的signal，导致loss没有尽可能低。</li>
<li>过度拟合训练集是指由于模型学习了太多的噪声，导致loss没有尽可能低。</li>
</ol>
<p>训练深度学习模型的诀窍是在两者之间找到最佳平衡，我们将研究几种从训练数据中获取更多signal的方法，同时减少噪声。</p>
<h3 id="capacity">Capacity<a hidden class="anchor" aria-hidden="true" href="#capacity">#</a></h3>
<p>模型的容量是指它能够学习的模式的大小和复杂性，对于神经网络来说，这在很大程度上取决于它有多少神经元以及它们如何连接在一起。如果网络似乎不适合数据，应该尝试增加其容量。</p>
<p>可以通过使网络更宽（将更多神经元添加到现有层）或使其更深（添加更多层）来增加网络的容量。更宽的网络更容易学习更多的线性关系，而更深的网络更喜欢非线性关系。哪个更好取决于数据集。</p>
<pre><code class="language-python">model = keras.Sequential([
    layers.Dense(16, activation='relu'),
    layers.Dense(1),
])

wider = keras.Sequential([
    layers.Dense(32, activation='relu'),
    layers.Dense(1),
])

deeper = keras.Sequential([
    layers.Dense(16, activation='relu'),
    layers.Dense(16, activation='relu'),
    layers.Dense(1),
])
</code></pre>
<h3 id="early-stopping">Early Stopping<a hidden class="anchor" aria-hidden="true" href="#early-stopping">#</a></h3>
<p>当模型学习到很多噪声时，验证损失可能会在训练期间开始增加，为了防止这种情况，只要验证loss似乎不再减少，我们就可以停止训练。以这种方式中断训练被称为<strong>提前停止</strong>（Early Stopping）。</p>
<p>
<img loading="lazy" src="https://s1.ax1x.com/2022/03/26/qUYIwd.png" alt="让模型在验证loss最小的位置停止"   /></p>
<p>一旦检测到了验证loss再次上升，就可以将权重重置回之前loss最小值的位置，确保了模型不会继续过拟合。</p>
<h3 id="adding-early-stopping">Adding Early Stopping<a hidden class="anchor" aria-hidden="true" href="#adding-early-stopping">#</a></h3>
<p>在Keras中，我们通过<strong>回调</strong>（callback）在训练中提前停止，回调函数是一个在网络运行时需要经常运行的函数。提前停止回调将在每个epoch之后运行。（Keras预先定义了各种有用的回调，也可以定义自己的回调。）</p>
<pre><code class="language-python">from tensorflow.keras.callbacks import EarlyStopping

early_stopping = EarlyStopping(
    min_delta=0.001, # minimium amount of change to count as an improvement
    patience=20, # 20个
    restore_best_weights=True,
)
</code></pre>
<p>如果在过去20个epochs中，验证loss没有改善0.001，那么停止训练，保留找到的最佳模型。</p>
<h3 id="example---train-a-model-with-early-stopping">Example - Train a Model with Early Stopping<a hidden class="anchor" aria-hidden="true" href="#example---train-a-model-with-early-stopping">#</a></h3>
<pre><code class="language-python">from tensorflow import keras
from tensorflow.keras import layers, callbacks

early_stopping = callbacks.EarlyStopping(
    min_delta=0.001, # minimium amount of change to count as an improvement
    patience=20, # how many epochs to wait before stopping
    restore_best_weights=True,
)

model = keras.Sequential([
    layers.Dense(512, activation='relu', input_shape=[11]),
    layers.Dense(512, activation='relu'),
    layers.Dense(512, activation='relu'),
    layers.Dense(1),
])
model.compile(
    optimizer='adam',
    loss='mae',
)
history = model.fit(
    X_train, y_train,
    validation_data=(X_valid, y_valid),
    batch_size=256,
    epochs=500,
    callbacks=[early_stopping], # put your callbacks in a list
    verbose=0,  # turn off training log
)

history_df = pd.DataFrame(history.history)
history_df.loc[:, ['loss', 'val_loss']].plot();
print(&quot;Minimum validation loss: {}&quot;.format(history_df['val_loss'].min()))
</code></pre>
<h2 id="dropout-and-batch-normalization">Dropout and Batch Normalization<a hidden class="anchor" aria-hidden="true" href="#dropout-and-batch-normalization">#</a></h2>
<p>keras有几十中layers，可以在 <a href="https://www.tensorflow.org/api_docs/python/tf/keras/layers/">Keras docs</a> 中查看示例。这一节将介绍两种特殊的layer，它们本身不包含神经元。</p>
<h3 id="dropout">Dropout<a hidden class="anchor" aria-hidden="true" href="#dropout">#</a></h3>
<p>Dropout可以帮助修正overfitting。</p>
<p>前面讲过了数据的欠拟合和过拟合，出现了过拟合的情况，是因为网络模型学习了训练数据中的虚假的模式（噪声的模式），模型为了学习到这个模式 通常会依赖非常特定的权重组合，所以这种权重的组合才实现出的模式，往往是很脆弱的，移除一个就会瓦解。</p>
<p>Dropout就是在训练的每一步都随机删除一层输入单元的一小部分，这使得网络更难从训练数据中学习这些虚假模式。相反，它必须寻找广泛的、一般的模式，其权重模式往往更稳健。</p>
<p>
<img loading="lazy" src="https://images.slightwind.cn/blog/kaggle/a86utxY.gif" alt="Here, 50% dropout has been added between the two hidden layers."   /></p>
<h3 id="adding-dropout">Adding Dropout<a hidden class="anchor" aria-hidden="true" href="#adding-dropout">#</a></h3>
<p>在Keras中，dropout率参数<code>rate</code>定义了要关闭的输入单元的百分比。将<code>Dropout layer</code>放在要应用Dropout的层之前：</p>
<pre><code class="language-python">keras.Sequential([
    # ...
    layers.Dropout(rate=0.3), # apply 30% dropout to the next layer
    layers.Dense(16),
    # ...
])
</code></pre>
<h3 id="batch-normalization">Batch Normalization<a hidden class="anchor" aria-hidden="true" href="#batch-normalization">#</a></h3>
<p>&ldquo;batch normalization&quot;或称&quot;batchnorm&quot;这个特殊层有助于纠正缓慢或不稳定的训练。在神经网络中通常需要将所有的数据放在一个通用的尺度上，可以使用scikit learn的StandardScaler或MinMaxScaler之类的工具，这是因为SGD根据数据产生的激活量按比例改变网络中的权重，训练中的数值大小范围不一样可能会导致不稳定的训练。</p>
<p>可以在数据进入网络之前对其进行规范化（normalize），但是更好的操作是在网络的内部对数据进行规范化，<strong>batch normalization layer</strong>就是用来对网络中的数据进行规范化操作的，它会用其自身的<strong>平均值</strong>和<strong>标准差</strong>对batch进行标准化，然后用两个可训练的重缩放参数（trainable rescaling parameters）将数据放在一个新的尺度上。</p>
<p>使用batchnorm的模型往往需要较少的时间完成训练，也可以解决可能导致训练“停滞”的各种问题，所以可以考虑在模型中添加batchnorm。</p>
<h3 id="adding-batch-normalization">Adding Batch Normalization<a hidden class="anchor" aria-hidden="true" href="#adding-batch-normalization">#</a></h3>
<p>batchnorm可以放在相对其他层的各种位置上，如果用它作为网络的第一层，就起到了一个代替预处理时对数据进行标准化的操作，类似Sci-Kit Learn的 <code>StandardScaler</code>，也可以放在某一层之后：</p>
<pre><code class="language-python">layers.Dense(16, activation='relu'),
layers.BatchNormalization(),
</code></pre>
<p>或在某层和它的激活函数之间：</p>
<pre><code class="language-python">layers.Dense(16),
layers.BatchNormalization(),
layers.Activation('relu'),
</code></pre>
<h3 id="example---using-dropout-and-batch-normalization">Example - Using Dropout and Batch Normalization<a hidden class="anchor" aria-hidden="true" href="#example---using-dropout-and-batch-normalization">#</a></h3>
<p>如果模型中使用了dropout，就应该在层中添加更多的单元，因为每次都会被随机抛弃一部分不参与的单元。</p>
<pre><code class="language-python">from tensorflow import keras
from tensorflow.keras import layers

model = keras.Sequential([
    layers.Dense(1024, activation='relu', input_shape=[11]),
    layers.Dropout(0.3),
    layers.BatchNormalization(),
    layers.Dense(1024, activation='relu'),
    layers.Dropout(0.3),
    layers.BatchNormalization(),
    layers.Dense(1024, activation='relu'),
    layers.Dropout(0.3),
    layers.BatchNormalization(),
    layers.Dense(1),
])

model.compile(
    optimizer='adam',
    loss='mae',
)

history = model.fit(
    X_train, y_train,
    validation_data=(X_valid, y_valid),
    batch_size=256,
    epochs=100,
    verbose=0,
)

# Show the learning curves
history_df = pd.DataFrame(history.history)
history_df.loc[:, ['loss', 'val_loss']].plot();
</code></pre>
<h2 id="binary-classification">Binary Classification<a hidden class="anchor" aria-hidden="true" href="#binary-classification">#</a></h2>
<h3 id="introduction-1">Introduction<a hidden class="anchor" aria-hidden="true" href="#introduction-1">#</a></h3>
<p>之前的部分在介绍用深度学习解决回归问题，这一节介绍用深度学习解决分类问题。</p>
<h3 id="binary-classification-1">Binary Classification<a hidden class="anchor" aria-hidden="true" href="#binary-classification-1">#</a></h3>
<p>二分类问题是指分成两类的问题，比如用&quot;Yes&rdquo;/&ldquo;No&quot;来回答的问题。我们需要给数据<strong>class label</strong>：0 或 1，数字标签是神经网络模型可以使用的数据形式。</p>
<h3 id="accuracy-and-cross-entropy">Accuracy and Cross-Entropy<a hidden class="anchor" aria-hidden="true" href="#accuracy-and-cross-entropy">#</a></h3>
<p><strong>准确性</strong>（Accuracy）是衡量分类问题成功与否的众多指标之一。accuracy是正确预测与总预测的比率：<code>accuracy = number_correct / total</code>。一个总是正确预测的模型的准确度得分为<code>1.0</code>。在所有其他条件相同的情况下，每当数据集中的类以大约相同的频率出现时，准确度是一个合理的指标。</p>
<p>accuracy（以及大多数其他分类指标）的问题在于，它不能用作损失函数。SGD需要一个平稳变化的损失函数，但精度，作为计数的比率，在“跳跃”中变化。因此，我们必须选择一个替代品作为损失函数。这个替代品是交叉熵函数（cross-entropy function）。</p>
<p>现在，回想一下损失函数定义了训练期间网络的目标。通过回归，我们的目标是最小化预期结果和预测结果之间的距离。我们选择了MAE来测量这个距离。</p>
<p>对于分类，我们想要的是概率之间的距离，这就是交叉熵提供的。<strong>Cross-entropy</strong>是一种度量从一个概率分布到另一个概率分布的距离的方法。</p>
<p>
<img loading="lazy" src="https://s1.ax1x.com/2022/03/26/qUYhOe.png" alt="Cross-entropy penalizes incorrect probability predictions."   /></p>
<p>我们希望我们的网络以<code>1.0</code>的概率预测正确的班级。预测概率离<code>1.0</code>越远，交叉熵损失越大。</p>
<p>我们使用交叉熵的技术原因有点微妙，但从这一节中我们要了解的主要内容是：使用交叉熵来进行分类损失；你可能关心的其他指标（如准确性）也会随之提高。</p>
<h3 id="making-probabilities-with-the-sigmoid-function">Making Probabilities with the Sigmoid Function<a hidden class="anchor" aria-hidden="true" href="#making-probabilities-with-the-sigmoid-function">#</a></h3>
<p>交叉熵和精度函数都需要概率作为输入，即0到1之间的数字。为了将密集层产生的实值输出转化为概率，我们附加了一种新的激活函数，即sigmoid激活函数。</p>
<p>
<img loading="lazy" src="https://s1.ax1x.com/2022/03/26/qUY7FI.png" alt="The sigmoid function maps real numbers into the interval [0,1]."   /></p>
<p>为了得到最终的类预测，我们定义了一个阈值概率。通常这将是0.5，因此四舍五入将为我们提供正确的类别：低于0.5表示标签为0的类别，0.5或以上表示标签为1的类别。0.5阈值是Keras默认使用的精度指标。</p>
<h3 id="example---binary-classification">Example - Binary Classification<a hidden class="anchor" aria-hidden="true" href="#example---binary-classification">#</a></h3>
<p>除了最后一层用了“sigmoid”激活，它用来产生类概率，其他部分和回归任务一样。</p>
<pre><code class="language-python">from tensorflow import keras
from tensorflow.keras import layers

model = keras.Sequential([
    layers.Dense(4, activation='relu', input_shape=[33]),
    layers.Dense(4, activation='relu'),    
    layers.Dense(1, activation='sigmoid'),
])

model.compile(
    optimizer='adam',              # Adam也适用于分类问题
    loss='binary_crossentropy',    # 损失函数为 交叉熵函数
    metrics=['binary_accuracy'],
)

# 提前停止 回调函数
early_stopping = keras.callbacks.EarlyStopping(
    patience=10,
    min_delta=0.001,
    restore_best_weights=True,
)

history = model.fit(
    X_train, y_train,
    validation_data=(X_valid, y_valid),
    batch_size=512,
    epochs=1000,
    callbacks=[early_stopping],
    verbose=0, # hide the output because we have so many epochs
)

history_df = pd.DataFrame(history.history)
# Start the plot at epoch 5
history_df.loc[5:, ['loss', 'val_loss']].plot()
history_df.loc[5:, ['binary_accuracy', 'val_binary_accuracy']].plot()

print((&quot;Best Validation Loss: {:0.4f}&quot; +\
      &quot;\nBest Validation Accuracy: {:0.4f}&quot;)\
      .format(history_df['val_loss'].min(), 
              history_df['val_binary_accuracy'].max()))

</code></pre>
<pre><code>Best Validation Loss: 0.5482
Best Validation Accuracy: 0.7619
</code></pre>
<img src="https://s1.ax1x.com/2022/03/26/qUYDeJ.png">
<img src="https://s1.ax1x.com/2022/03/26/qUYwyF.png">
<h2 id="detecting-the-higgs-boson-with-tpus">Detecting the Higgs Boson With TPUs<a hidden class="anchor" aria-hidden="true" href="#detecting-the-higgs-boson-with-tpus">#</a></h2>
<p>这是属于Intro to Deep Learning的一节Bonus Lesson，介绍如何使用TPU的。</p>
<pre><code class="language-python"># TensorFlow
import tensorflow as tf
print(&quot;Tensorflow version &quot; + tf.__version__)

# Detect and init the TPU
try: # detect TPUs
    tpu = tf.distribute.cluster_resolver.TPUClusterResolver.connect() # TPU detection
    strategy = tf.distribute.TPUStrategy(tpu)
except ValueError: # detect GPUs
    strategy = tf.distribute.get_strategy() # default strategy that works on CPU and single GPU
print(&quot;Number of accelerators: &quot;, strategy.num_replicas_in_sync)
</code></pre>
<h1 id="computer-vision">Computer Vision<a hidden class="anchor" aria-hidden="true" href="#computer-vision">#</a></h1>
<h2 id="the-convolutional-classifier">The Convolutional Classifier<a hidden class="anchor" aria-hidden="true" href="#the-convolutional-classifier">#</a></h2>
<h3 id="introduction-2">Introduction<a hidden class="anchor" aria-hidden="true" href="#introduction-2">#</a></h3>
<p>卷积神经网络（convolutional neural networks）是最擅长理解图像的神经网络，我们称之为convent或CNN。卷积是一种数学运算，它使网络的各层具有独特的结构。</p>
<h3 id="the-convolutional-classifier-1">The Convolutional Classifier<a hidden class="anchor" aria-hidden="true" href="#the-convolutional-classifier-1">#</a></h3>
<p>用于图像分类的convnet由两部分组成：<strong>convolutional base</strong> 和 <strong>dense head</strong>。</p>
<img src="https://s1.ax1x.com/2022/03/26/qwPXHe.png">
<ul>
<li>Base用于<strong>从图像中提取特征</strong>，它主要由执行卷积运算的层组成，但通常也包括其他类型的层。</li>
<li>Head用于<strong>确定图像的类别</strong>，它主要由致密层构成，但也可能包括其他层，如脱落层。</li>
</ul>
<p>特征可以是线条、颜色、纹理、形状、图案，也可以是一些复杂的组合。</p>
<img src="https://s1.ax1x.com/2022/03/26/qwFrQ0.png">
<h3 id="training-the-classifier">Training the Classifier<a hidden class="anchor" aria-hidden="true" href="#training-the-classifier">#</a></h3>
<p>训练期间网络的目标是学习两件事：</p>
<ol>
<li>要从图像中提取哪些特征 (base)，</li>
<li>哪一类与哪些特征相匹配 (head)。</li>
</ol>
<p>如今，convnet很少从零开始训练。更常见的情况是，我们重用预训练模型的基础。然后，我们在预先训练好的Base加上一个未经训练的Head。换句话说，我们重用网络中已经学会做<em>提取特征</em>的层，并附加一些新的层来学习<em>分类</em>。</p>
<div align="center"><img style="width:50%" src="https://s1.ax1x.com/2022/03/26/qwFBzq.png"></div>
<p>因为头部通常只有几个密集的层，所以可以从相对较少的数据中创建非常精确的分类器。</p>
<p><strong>迁移学习</strong>就是一种重用预先训练好的模型的技术。它非常有效，现在几乎所有的图像分类器都会使用它。</p>
<h3 id="example---train-a-convnet-classifier">Example - Train a Convnet Classifier<a hidden class="anchor" aria-hidden="true" href="#example---train-a-convnet-classifier">#</a></h3>
<p>我们将创建一个用于分类汽车和卡车的分类器，数据集是大约10000张图片，其中汽车和卡车的几乎各占一半。</p>
<h4 id="step-1---load-data">Step 1 - Load Data<a hidden class="anchor" aria-hidden="true" href="#step-1---load-data">#</a></h4>
<pre><code class="language-python"># 导入一些包
import os, warnings
import matplotlib.pyplot as plt
from matplotlib import gridspec

import numpy as np
import tensorflow as tf
from tensorflow.keras.preprocessing import image_dataset_from_directory

# 设置固定的种子，来保证可复现性
def set_seed(seed=31415):
    np.random.seed(seed)
    tf.random.set_seed(seed)
    os.environ['PYTHONHASHSEED'] = str(seed)
    os.environ['TF_DETERMINISTIC_OPS'] = '1'
set_seed(31415)

# 设置 Matplotlib 的默认值
plt.rc('figure', autolayout=True)
plt.rc('axes', labelweight='bold', labelsize='large',
       titleweight='bold', titlesize=18, titlepad=10)
plt.rc('image', cmap='magma')
warnings.filterwarnings(&quot;ignore&quot;) # to clean up output cells

# Load training and validation sets
ds_train_ = image_dataset_from_directory(
    '../input/car-or-truck/train',  # 文件夹
    labels='inferred',
    label_mode='binary',
    image_size=[128, 128],          # 图片大小
    interpolation='nearest',
    batch_size=64,
    shuffle=True,
)
ds_valid_ = image_dataset_from_directory(
    '../input/car-or-truck/valid',
    labels='inferred',
    label_mode='binary',
    image_size=[128, 128],
    interpolation='nearest',
    batch_size=64,
    shuffle=False,
)

# Data Pipeline
def convert_to_float(image, label):
    image = tf.image.convert_image_dtype(image, dtype=tf.float32)
    return image, label

AUTOTUNE = tf.data.experimental.AUTOTUNE
ds_train = (
    ds_train_
    .map(convert_to_float)
    .cache()
    .prefetch(buffer_size=AUTOTUNE)
)
ds_valid = (
    ds_valid_
    .map(convert_to_float)
    .cache()
    .prefetch(buffer_size=AUTOTUNE)
)
</code></pre>
<h4 id="step-2---define-pretrained-base">Step 2 - Define Pretrained Base<a hidden class="anchor" aria-hidden="true" href="#step-2---define-pretrained-base">#</a></h4>
<p>最常用的预训练数据集是<a href="http://image-net.org/about-overview">ImageNet</a>，这是一个包含多种自然图像的大型数据集。Keras在其 <code>applications</code>模块中包含在ImageNet上预训练的各种模型。我们将使用的预训练模型称为<strong>VGG16</strong>。</p>
<pre><code class="language-python">pretrained_base = tf.keras.models.load_model(
    '../input/cv-course-models/cv-course-models/vgg16-pretrained-base',
)
pretrained_base.trainable = False
</code></pre>
<p><a href="https://www.tensorflow.org/api_docs/python/tf/keras/applications/vgg16/VGG16">VGG16</a>也可以这样直接调用：</p>
<pre><code class="language-python">tf.keras.applications.vgg16.VGG16(
    include_top=True,
    weights='imagenet',
    input_tensor=None,
    input_shape=None,
    pooling=None,
    classes=1000,
    classifier_activation='softmax'
)
</code></pre>
<h4 id="step-3---attach-head">Step 3 - Attach Head<a hidden class="anchor" aria-hidden="true" href="#step-3---attach-head">#</a></h4>
<p>接下来连接分类器head。先用一个<code>Flatten</code>层，把前面二维的输出转化为一维来提供给后面的层。然后是一个隐藏层，最后一层（输出层）把输出转换为判断是<code>Truck</code>的概率分数。</p>
<pre><code class="language-python">from tensorflow import keras
from tensorflow.keras import layers

model = keras.Sequential([
    pretrained_base,
    layers.Flatten(),
    layers.Dense(6, activation='relu'),
    layers.Dense(1, activation='sigmoid'),
])
</code></pre>
<h4 id="step-4---train">Step 4 - Train<a hidden class="anchor" aria-hidden="true" href="#step-4---train">#</a></h4>
<p>由于这是一个分成两类的问题，所以我们使用二进制版本的<code>crossentropy</code>和<code>accuracy</code>。</p>
<pre><code class="language-python">model.compile(
    optimizer='adam',
    loss='binary_crossentropy',   # 损失函数
    metrics=['binary_accuracy'],  # 准确度评估
)

history = model.fit(
    ds_train,
    validation_data=ds_valid,
    epochs=30,
    verbose=0,
)
</code></pre>
<p>在训练神经网络模型时，最好检查loss和metric曲线，变化过程被存储在<code>history.history</code>中，可以这样把它们显示出来：</p>
<pre><code class="language-python">import pandas as pd

history_frame = pd.DataFrame(history.history)
history_frame.loc[:, ['loss', 'val_loss']].plot()
history_frame.loc[:, ['binary_accuracy', 'val_binary_accuracy']].plot();
</code></pre>
<img src="https://s1.ax1x.com/2022/03/26/qwFwJs.png">
<img src="https://s1.ax1x.com/2022/03/26/qwF0Wn.png">
<h2 id="convolution-and-relu">Convolution and ReLU<a hidden class="anchor" aria-hidden="true" href="#convolution-and-relu">#</a></h2>
<p>前一节我们了解到卷积分类器有两部分：base和head，base从图像中提取特征，head使用这些特征对图像分类。</p>
<p>后面的几节教程会介绍base部分 最重要的两种类型的层，它们分别是：具有ReLU激活的卷积层 和 最大池化层。第5节教程将会介绍通过这些层的组合来进行特征提取（Base部分）。</p>
<p>这一节是关于卷积层和ReLU激活函数的。</p>
<h3 id="feature-extraction">Feature Extraction<a hidden class="anchor" aria-hidden="true" href="#feature-extraction">#</a></h3>
<p>由base执行的特征提取包括三个基本操作：</p>
<ol>
<li>针对特定特征<strong>过滤</strong>（filter）图像（卷积）</li>
<li>在过滤后的图像中<strong>检测</strong>（detect）该特征（ReLU）</li>
<li><strong>压缩</strong>（condense）图像以增强特征（最大池化）</li>
</ol>
<p>下图说明了这个过程，可以看到这三个操作是如何隔离原始图像的某些特定特征的（在本例中为水平线）。</p>
<div align="center"><img style="width:50%" src="https://s1.ax1x.com/2022/03/27/qBmJc4.jpg"></div>
<p>通常网络会在一个图片上并行的提取，在一些现代的convnets中，最后一层产生1000多个独特的视觉特征也很多见。</p>
<h3 id="filter-with-convolution">Filter with Convolution<a hidden class="anchor" aria-hidden="true" href="#filter-with-convolution">#</a></h3>
<p>卷积层执行滤波步骤,可以在Keras模型中定义一个卷积层：</p>
<pre><code class="language-python">from tensorflow import keras
from tensorflow.keras import layers

model = keras.Sequential([
    layers.Conv2D(filters=64, kernel_size=3), # activation is None
    # More layers follow
])
</code></pre>
<p>我们可以通过观察这些参数与层的权重和激活的关系来理解这些参数。</p>
<h4 id="weights">Weights<a hidden class="anchor" aria-hidden="true" href="#weights">#</a></h4>
<p>convnet在训练期间学习的权重主要包含在其卷积层中，这些<strong>权重</strong>我们称之为核（kernels），我们可以将它们表示为小数组：</p>
<div align="center"><img style="width:20%" src="https://s1.ax1x.com/2022/03/27/qBm1hT.png"></div>
<p><strong>kernel</strong>通过扫描图像并产生像素值的加权和来运行。通过这种方式，内核将像偏振光透镜一样，强调或不强调某些信息模式。</p>
<div align="center"><img style="width:30%" src="https://s1.ax1x.com/2022/03/27/qBmG3F.png"></div>
<p>Kernels定义了卷积层如何连接到后面的层，上图中的kernel将前一层的9个神经元的输出，加权求和得到一个值输入到了后面层的一个神经元。我们可以使用<code>kernel_size</code>来设置kernel的维度，大多数情况下，kernel的维数都是奇数，如<code>(3, 3)</code>，<code>(5, 5)</code>，因此只有一个像素位于中心，但这并不是必须的。</p>
<p>卷积层的kernel决定了它创建的特征类型，在训练期间，convent会尝试解决当前分类问题所需要的特征，这也意味着kernel的最佳取值。</p>
<h3 id="activations">Activations<a hidden class="anchor" aria-hidden="true" href="#activations">#</a></h3>
<p>网络中的激活（activation），我们称之为特征映射（feature maps），它们是我们对图像应用过滤器时的结果；它们包含kernel提取的视觉特征。下面是一些kernel及其生成的特征映射：</p>
<div align="center"><img style="width:80%" src="https://s1.ax1x.com/2022/03/27/qBm89U.png"></div>
<p>从kernel中的数字的模式，可以看出它创建的特征映射的类型。通常，卷积在其输入中强调的内容将与内核中正数的形状相匹配。上面的左核和中核都将过滤水平形状。</p>
<p>使用filters参数，可以告诉卷积层希望它创建多少个特征贴图作为输出。</p>
<!-- ### Detect with ReLU

<div align="center"><img style="width:40%" src="https://s1.ax1x.com/2022/03/27/qBmK7q.png"></div>


![](https://s1.ax1x.com/2022/03/27/qBmE9S.png)
![](https://s1.ax1x.com/2022/03/27/qBmkh8.png)
![](https://s1.ax1x.com/2022/03/27/qBmZcQ.png)
![](https://s1.ax1x.com/2022/03/27/qBmV1g.png)
![](https://s1.ax1x.com/2022/03/27/qBmFtf.png)
![](https://s1.ax1x.com/2022/03/27/qBmeXj.png)
![](https://s1.ax1x.com/2022/03/27/qBmuBn.png)
![](https://s1.ax1x.com/2022/03/27/qBmnns.png)
![](https://s1.ax1x.com/2022/03/27/qBmQA0.png)
![](https://s1.ax1x.com/2022/03/27/qBmlNV.png) -->


  </div>

  <footer class="post-footer">
    <ul class="post-tags">
      <li><a href="https://blog.slightwind.cn/tags/notes/">Notes</a></li>
      <li><a href="https://blog.slightwind.cn/tags/kaggle/">Kaggle</a></li>
      <li><a href="https://blog.slightwind.cn/tags/dl/">DL</a></li>
      <li><a href="https://blog.slightwind.cn/tags/computer-vision/">Computer Vision</a></li>
    </ul>
<nav class="paginav">
  <a class="next" href="https://blog.slightwind.cn/posts/tutorial/notes-kaggle-courses-intro-to-ml/">
    <span class="title">Next »</span>
    <br>
    <span>Notes: Kaggle Courses - Intro to ML &amp; Intermediate ML</span>
  </a>
</nav>


<div class="share-buttons">
    <a target="_blank" rel="noopener noreferrer" aria-label="share Notes: Kaggle Courses - Intro to DL &amp; Computer Vision on x"
        href="https://x.com/intent/tweet/?text=Notes%3a%20Kaggle%20Courses%20-%20Intro%20to%20DL%20%26%20Computer%20Vision&amp;url=https%3a%2f%2fblog.slightwind.cn%2fposts%2ftutorial%2fnotes-kaggle-courses-intro-to-dl%2f&amp;hashtags=Notes%2cKaggle%2cDL%2cComputerVision">
        <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
            <path
                d="M512 62.554 L 512 449.446 C 512 483.97 483.97 512 449.446 512 L 62.554 512 C 28.03 512 0 483.97 0 449.446 L 0 62.554 C 0 28.03 28.029 0 62.554 0 L 449.446 0 C 483.971 0 512 28.03 512 62.554 Z M 269.951 190.75 L 182.567 75.216 L 56 75.216 L 207.216 272.95 L 63.9 436.783 L 125.266 436.783 L 235.9 310.383 L 332.567 436.783 L 456 436.783 L 298.367 228.367 L 432.367 75.216 L 371.033 75.216 Z M 127.633 110 L 164.101 110 L 383.481 400.065 L 349.5 400.065 Z"/>
        </svg>
    </a>
    <a target="_blank" rel="noopener noreferrer" aria-label="share Notes: Kaggle Courses - Intro to DL &amp; Computer Vision on linkedin"
        href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https%3a%2f%2fblog.slightwind.cn%2fposts%2ftutorial%2fnotes-kaggle-courses-intro-to-dl%2f&amp;title=Notes%3a%20Kaggle%20Courses%20-%20Intro%20to%20DL%20%26%20Computer%20Vision&amp;summary=Notes%3a%20Kaggle%20Courses%20-%20Intro%20to%20DL%20%26%20Computer%20Vision&amp;source=https%3a%2f%2fblog.slightwind.cn%2fposts%2ftutorial%2fnotes-kaggle-courses-intro-to-dl%2f">
        <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
            <path
                d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-288.985,423.278l0,-225.717l-75.04,0l0,225.717l75.04,0Zm270.539,0l0,-129.439c0,-69.333 -37.018,-101.586 -86.381,-101.586c-39.804,0 -57.634,21.891 -67.617,37.266l0,-31.958l-75.021,0c0.995,21.181 0,225.717 0,225.717l75.02,0l0,-126.056c0,-6.748 0.486,-13.492 2.474,-18.315c5.414,-13.475 17.767,-27.434 38.494,-27.434c27.135,0 38.007,20.707 38.007,51.037l0,120.768l75.024,0Zm-307.552,-334.556c-25.674,0 -42.448,16.879 -42.448,39.002c0,21.658 16.264,39.002 41.455,39.002l0.484,0c26.165,0 42.452,-17.344 42.452,-39.002c-0.485,-22.092 -16.241,-38.954 -41.943,-39.002Z" />
        </svg>
    </a>
    <a target="_blank" rel="noopener noreferrer" aria-label="share Notes: Kaggle Courses - Intro to DL &amp; Computer Vision on reddit"
        href="https://reddit.com/submit?url=https%3a%2f%2fblog.slightwind.cn%2fposts%2ftutorial%2fnotes-kaggle-courses-intro-to-dl%2f&title=Notes%3a%20Kaggle%20Courses%20-%20Intro%20to%20DL%20%26%20Computer%20Vision">
        <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
            <path
                d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-3.446,265.638c0,-22.964 -18.616,-41.58 -41.58,-41.58c-11.211,0 -21.361,4.457 -28.841,11.666c-28.424,-20.508 -67.586,-33.757 -111.204,-35.278l18.941,-89.121l61.884,13.157c0.756,15.734 13.642,28.29 29.56,28.29c16.407,0 29.706,-13.299 29.706,-29.701c0,-16.403 -13.299,-29.702 -29.706,-29.702c-11.666,0 -21.657,6.792 -26.515,16.578l-69.105,-14.69c-1.922,-0.418 -3.939,-0.042 -5.585,1.036c-1.658,1.073 -2.811,2.761 -3.224,4.686l-21.152,99.438c-44.258,1.228 -84.046,14.494 -112.837,35.232c-7.468,-7.164 -17.589,-11.591 -28.757,-11.591c-22.965,0 -41.585,18.616 -41.585,41.58c0,16.896 10.095,31.41 24.568,37.918c-0.639,4.135 -0.99,8.328 -0.99,12.576c0,63.977 74.469,115.836 166.33,115.836c91.861,0 166.334,-51.859 166.334,-115.836c0,-4.218 -0.347,-8.387 -0.977,-12.493c14.564,-6.47 24.735,-21.034 24.735,-38.001Zm-119.474,108.193c-20.27,20.241 -59.115,21.816 -70.534,21.816c-11.428,0 -50.277,-1.575 -70.522,-21.82c-3.007,-3.008 -3.007,-7.882 0,-10.889c3.003,-2.999 7.882,-3.003 10.885,0c12.777,12.781 40.11,17.317 59.637,17.317c19.522,0 46.86,-4.536 59.657,-17.321c3.016,-2.999 7.886,-2.995 10.885,0.008c3.008,3.011 3.003,7.882 -0.008,10.889Zm-5.23,-48.781c-16.373,0 -29.701,-13.324 -29.701,-29.698c0,-16.381 13.328,-29.714 29.701,-29.714c16.378,0 29.706,13.333 29.706,29.714c0,16.374 -13.328,29.698 -29.706,29.698Zm-160.386,-29.702c0,-16.381 13.328,-29.71 29.714,-29.71c16.369,0 29.689,13.329 29.689,29.71c0,16.373 -13.32,29.693 -29.689,29.693c-16.386,0 -29.714,-13.32 -29.714,-29.693Z" />
        </svg>
    </a>
    <a target="_blank" rel="noopener noreferrer" aria-label="share Notes: Kaggle Courses - Intro to DL &amp; Computer Vision on facebook"
        href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2fblog.slightwind.cn%2fposts%2ftutorial%2fnotes-kaggle-courses-intro-to-dl%2f">
        <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
            <path
                d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-106.468,0l0,-192.915l66.6,0l12.672,-82.621l-79.272,0l0,-53.617c0,-22.603 11.073,-44.636 46.58,-44.636l36.042,0l0,-70.34c0,0 -32.71,-5.582 -63.982,-5.582c-65.288,0 -107.96,39.569 -107.96,111.204l0,62.971l-72.573,0l0,82.621l72.573,0l0,192.915l-191.104,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Z" />
        </svg>
    </a>
    <a target="_blank" rel="noopener noreferrer" aria-label="share Notes: Kaggle Courses - Intro to DL &amp; Computer Vision on whatsapp"
        href="https://api.whatsapp.com/send?text=Notes%3a%20Kaggle%20Courses%20-%20Intro%20to%20DL%20%26%20Computer%20Vision%20-%20https%3a%2f%2fblog.slightwind.cn%2fposts%2ftutorial%2fnotes-kaggle-courses-intro-to-dl%2f">
        <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
            <path
                d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-58.673,127.703c-33.842,-33.881 -78.847,-52.548 -126.798,-52.568c-98.799,0 -179.21,80.405 -179.249,179.234c-0.013,31.593 8.241,62.428 23.927,89.612l-25.429,92.884l95.021,-24.925c26.181,14.28 55.659,21.807 85.658,21.816l0.074,0c98.789,0 179.206,-80.413 179.247,-179.243c0.018,-47.895 -18.61,-92.93 -52.451,-126.81Zm-126.797,275.782l-0.06,0c-26.734,-0.01 -52.954,-7.193 -75.828,-20.767l-5.441,-3.229l-56.386,14.792l15.05,-54.977l-3.542,-5.637c-14.913,-23.72 -22.791,-51.136 -22.779,-79.287c0.033,-82.142 66.867,-148.971 149.046,-148.971c39.793,0.014 77.199,15.531 105.329,43.692c28.128,28.16 43.609,65.592 43.594,105.4c-0.034,82.149 -66.866,148.983 -148.983,148.984Zm81.721,-111.581c-4.479,-2.242 -26.499,-13.075 -30.604,-14.571c-4.105,-1.495 -7.091,-2.241 -10.077,2.241c-2.986,4.483 -11.569,14.572 -14.182,17.562c-2.612,2.988 -5.225,3.364 -9.703,1.12c-4.479,-2.241 -18.91,-6.97 -36.017,-22.23c-13.314,-11.876 -22.304,-26.542 -24.916,-31.026c-2.612,-4.484 -0.279,-6.908 1.963,-9.14c2.016,-2.007 4.48,-5.232 6.719,-7.847c2.24,-2.615 2.986,-4.484 4.479,-7.472c1.493,-2.99 0.747,-5.604 -0.374,-7.846c-1.119,-2.241 -10.077,-24.288 -13.809,-33.256c-3.635,-8.733 -7.327,-7.55 -10.077,-7.688c-2.609,-0.13 -5.598,-0.158 -8.583,-0.158c-2.986,0 -7.839,1.121 -11.944,5.604c-4.105,4.484 -15.675,15.32 -15.675,37.364c0,22.046 16.048,43.342 18.287,46.332c2.24,2.99 31.582,48.227 76.511,67.627c10.685,4.615 19.028,7.371 25.533,9.434c10.728,3.41 20.492,2.929 28.209,1.775c8.605,-1.285 26.499,-10.833 30.231,-21.295c3.732,-10.464 3.732,-19.431 2.612,-21.298c-1.119,-1.869 -4.105,-2.99 -8.583,-5.232Z" />
        </svg>
    </a>
    <a target="_blank" rel="noopener noreferrer" aria-label="share Notes: Kaggle Courses - Intro to DL &amp; Computer Vision on telegram"
        href="https://telegram.me/share/url?text=Notes%3a%20Kaggle%20Courses%20-%20Intro%20to%20DL%20%26%20Computer%20Vision&amp;url=https%3a%2f%2fblog.slightwind.cn%2fposts%2ftutorial%2fnotes-kaggle-courses-intro-to-dl%2f">
        <svg version="1.1" xml:space="preserve" viewBox="2 2 28 28" height="30px" width="30px" fill="currentColor">
            <path
                d="M26.49,29.86H5.5a3.37,3.37,0,0,1-2.47-1,3.35,3.35,0,0,1-1-2.47V5.48A3.36,3.36,0,0,1,3,3,3.37,3.37,0,0,1,5.5,2h21A3.38,3.38,0,0,1,29,3a3.36,3.36,0,0,1,1,2.46V26.37a3.35,3.35,0,0,1-1,2.47A3.38,3.38,0,0,1,26.49,29.86Zm-5.38-6.71a.79.79,0,0,0,.85-.66L24.73,9.24a.55.55,0,0,0-.18-.46.62.62,0,0,0-.41-.17q-.08,0-16.53,6.11a.59.59,0,0,0-.41.59.57.57,0,0,0,.43.52l4,1.24,1.61,4.83a.62.62,0,0,0,.63.43.56.56,0,0,0,.4-.17L16.54,20l4.09,3A.9.9,0,0,0,21.11,23.15ZM13.8,20.71l-1.21-4q8.72-5.55,8.78-5.55c.15,0,.23,0,.23.16a.18.18,0,0,1,0,.06s-2.51,2.3-7.52,6.8Z" />
        </svg>
    </a>
    <a target="_blank" rel="noopener noreferrer" aria-label="share Notes: Kaggle Courses - Intro to DL &amp; Computer Vision on ycombinator"
        href="https://news.ycombinator.com/submitlink?t=Notes%3a%20Kaggle%20Courses%20-%20Intro%20to%20DL%20%26%20Computer%20Vision&u=https%3a%2f%2fblog.slightwind.cn%2fposts%2ftutorial%2fnotes-kaggle-courses-intro-to-dl%2f">
        <svg version="1.1" xml:space="preserve" width="30px" height="30px" viewBox="0 0 512 512" fill="currentColor"
            xmlns:inkscape="http://www.inkscape.org/namespaces/inkscape">
            <path
                d="M449.446 0C483.971 0 512 28.03 512 62.554L512 449.446C512 483.97 483.97 512 449.446 512L62.554 512C28.03 512 0 483.97 0 449.446L0 62.554C0 28.03 28.029 0 62.554 0L449.446 0ZM183.8767 87.9921H121.8427L230.6673 292.4508V424.0079H281.3328V292.4508L390.1575 87.9921H328.1233L256 238.2489z" />
        </svg>
    </a>
</div>

  </footer>
</article>
    </main>
    
<footer class="footer">
    <span>&copy; 2023 <a href="https://blog.slightwind.cn/">Slightwind</a></span>
    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
<script>
    document.querySelectorAll('pre > code').forEach((codeblock) => {
        const container = codeblock.parentNode.parentNode;

        const copybutton = document.createElement('button');
        copybutton.classList.add('copy-code');
        copybutton.innerHTML = 'copy';

        function copyingDone() {
            copybutton.innerHTML = 'copied!';
            setTimeout(() => {
                copybutton.innerHTML = 'copy';
            }, 2000);
        }

        copybutton.addEventListener('click', (cb) => {
            if ('clipboard' in navigator) {
                navigator.clipboard.writeText(codeblock.textContent);
                copyingDone();
                return;
            }

            const range = document.createRange();
            range.selectNodeContents(codeblock);
            const selection = window.getSelection();
            selection.removeAllRanges();
            selection.addRange(range);
            try {
                document.execCommand('copy');
                copyingDone();
            } catch (e) { };
            selection.removeRange(range);
        });

        if (container.classList.contains("highlight")) {
            container.appendChild(copybutton);
        } else if (container.parentNode.firstChild == container) {
            
        } else if (codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName == "TABLE") {
            
            codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(copybutton);
        } else {
            
            codeblock.parentNode.appendChild(copybutton);
        }
    });
</script>
</body>

</html>
